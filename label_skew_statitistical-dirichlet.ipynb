{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMShUIgF8fjy3wSka63W44U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiri9/non-iid/blob/main/label_skew_statitistical-dirichlet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow and all dependencies explicitly compatible with TFF 0.87.0\n",
        "%pip install tensorflow==2.15.0\n",
        "%pip install tensorflow-federated==0.81.0\n",
        "%pip install tensorflow-privacy==0.9.0\n",
        "%pip install tensorflow-model-optimization==0.7.5\n",
        "%pip install jax==0.4.14 jaxlib==0.4.14\n",
        "%pip install google-vizier==0.1.11\n",
        "%pip install dp-accounting==0.4.3\n",
        "%pip install portpicker==1.6.0\n",
        "%pip install scipy==1.9.3\n",
        "%pip install numpy==1.25.2\n",
        "%pip install protobuf==3.20.3\n",
        "%pip install typing-extensions==4.7.1\n",
        "%pip install googleapis-common-protos==1.61.0\n",
        "%pip install dm-tree==0.1.8"
      ],
      "metadata": {
        "id": "Gz8B4VFI9q3q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f54e86f-c54a-4787-d25b-3657562d14ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.25.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.13.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Collecting tensorflow-federated==0.81.0\n",
            "  Using cached tensorflow_federated-0.81.0-py3-none-manylinux_2_31_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: absl-py==1.*,>=1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-federated==0.81.0) (1.4.0)\n",
            "Collecting attrs~=23.1 (from tensorflow-federated==0.81.0)\n",
            "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: cachetools~=5.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-federated==0.81.0) (5.5.2)\n",
            "Collecting dm-tree==0.1.8 (from tensorflow-federated==0.81.0)\n",
            "  Using cached dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting dp-accounting==0.4.3 (from tensorflow-federated==0.81.0)\n",
            "  Using cached dp_accounting-0.4.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting google-vizier==0.1.11 (from tensorflow-federated==0.81.0)\n",
            "  Using cached google_vizier-0.1.11-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: grpcio~=1.46 in /usr/local/lib/python3.11/dist-packages (from tensorflow-federated==0.81.0) (1.71.0)\n",
            "Collecting jaxlib==0.4.14 (from tensorflow-federated==0.81.0)\n",
            "  Using cached jaxlib-0.4.14-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting jax==0.4.14 (from tensorflow-federated==0.81.0)\n",
            "  Downloading jax-0.4.14.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy~=1.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow-federated==0.81.0) (1.26.4)\n",
            "Collecting portpicker~=1.6 (from tensorflow-federated==0.81.0)\n",
            "  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting scipy~=1.9.3 (from tensorflow-federated==0.81.0)\n",
            "  Downloading scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-model-optimization==0.7.5 (from tensorflow-federated==0.81.0)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "Collecting tensorflow-privacy==0.9.0 (from tensorflow-federated==0.81.0)\n",
            "  Downloading tensorflow_privacy-0.9.0-py3-none-any.whl.metadata (763 bytes)\n",
            "Collecting tensorflow==2.14.*,>=2.14.0 (from tensorflow-federated==0.81.0)\n",
            "  Downloading tensorflow-2.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tqdm~=4.64 in /usr/local/lib/python3.11/dist-packages (from tensorflow-federated==0.81.0) (4.67.1)\n",
            "Collecting typing-extensions==4.5.*,>=4.5.0 (from tensorflow-federated==0.81.0)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting googleapis-common-protos==1.61.0 (from tensorflow-federated==0.81.0)\n",
            "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.11/dist-packages (from dp-accounting==0.4.3->tensorflow-federated==0.81.0) (1.3.0)\n",
            "Collecting attrs~=23.1 (from tensorflow-federated==0.81.0)\n",
            "  Using cached attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: protobuf>=3.6 in /usr/local/lib/python3.11/dist-packages (from google-vizier==0.1.11->tensorflow-federated==0.81.0) (4.25.7)\n",
            "Collecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow-federated==0.81.0)\n",
            "  Using cached grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting sqlalchemy<=1.4.20,>=1.4 (from google-vizier==0.1.11->tensorflow-federated==0.81.0)\n",
            "  Using cached SQLAlchemy-1.4.20.tar.gz (7.7 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ml_dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax==0.4.14->tensorflow-federated==0.81.0) (0.2.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax==0.4.14->tensorflow-federated==0.81.0) (3.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (18.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (3.1.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (0.37.1)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting packaging (from tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0)\n",
            "  Downloading packaging-22.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0->tensorflow-federated==0.81.0) (1.6.1)\n",
            "Collecting tensorflow-probability~=0.22.0 (from tensorflow-privacy==0.9.0->tensorflow-federated==0.81.0)\n",
            "  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow-federated==0.81.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow-federated==0.81.0) (3.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from portpicker~=1.6->tensorflow-federated==0.81.0) (5.9.5)\n",
            "Collecting numpy~=1.25 (from tensorflow-federated==0.81.0)\n",
            "  Downloading numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (0.45.1)\n",
            "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow-federated==0.81.0)\n",
            "  Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.68.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.67.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_tools-1.66.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_tools-1.65.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.62.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier==0.1.11->tensorflow-federated==0.81.0) (3.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (3.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow-federated==0.81.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow-federated==0.81.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow-federated==0.81.0) (3.2.2)\n",
            "Downloading tensorflow_federated-0.81.0-py3-none-manylinux_2_31_x86_64.whl (71.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dp_accounting-0.4.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_vizier-0.1.11-py3-none-any.whl (721 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.14-cp311-cp311-manylinux2014_x86_64.whl (73.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_privacy-0.9.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
            "Downloading scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.62.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: jax, sqlalchemy\n",
            "  Building wheel for jax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.4.14-py3-none-any.whl size=1535471 sha256=a99dd824c5a508fabf60bb49e474178e69e215c73984af8b54c47089895a8486\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/8d/5d/66b1fbb551b0c3a21696015b7339b8241ebfa128bb9145febd\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.4.20-cp311-cp311-linux_x86_64.whl size=1531744 sha256=a0f9a15f2e55843a967b58eee42744b792091ee0d9828cb4907bb0eba228fce5\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/a2/a2/9290912f40321acfd65cf7a741d2e0882e9a1f9464f60e2e9b\n",
            "Successfully built jax sqlalchemy\n",
            "Installing collected packages: dm-tree, typing-extensions, tensorflow-estimator, sqlalchemy, portpicker, packaging, numpy, keras, grpcio-tools, googleapis-common-protos, attrs, tensorflow-probability, tensorflow-model-optimization, scipy, google-vizier, jaxlib, jax, google-auth-oauthlib, dp-accounting, tensorboard, tensorflow, tensorflow-privacy, tensorflow-federated\n",
            "  Attempting uninstall: dm-tree\n",
            "    Found existing installation: dm-tree 0.1.9\n",
            "    Uninstalling dm-tree-0.1.9:\n",
            "      Successfully uninstalled dm-tree-0.1.9\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.40\n",
            "    Uninstalling SQLAlchemy-2.0.40:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.40\n",
            "  Attempting uninstall: portpicker\n",
            "    Found existing installation: portpicker 1.5.2\n",
            "    Uninstalling portpicker-1.5.2:\n",
            "      Successfully uninstalled portpicker-1.5.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.70.0\n",
            "    Uninstalling googleapis-common-protos-1.70.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.70.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.25.0\n",
            "    Uninstalling tensorflow-probability-0.25.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.25.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires portpicker==1.5.2, but you have portpicker 1.6.0 which is incompatible.\n",
            "pydantic 2.11.4 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "cvxpy 1.6.5 requires scipy>=1.11.0, but you have scipy 1.9.3 which is incompatible.\n",
            "xarray 2025.3.1 requires packaging>=23.2, but you have packaging 22.0 which is incompatible.\n",
            "orbax-checkpoint 0.11.13 requires jax>=0.5.0, but you have jax 0.4.14 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.9.3 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.20 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.14.1 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.14.1 which is incompatible.\n",
            "tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
            "langsmith 0.3.42 requires packaging>=23.2, but you have packaging 22.0 which is incompatible.\n",
            "google-cloud-bigquery 3.32.0 requires packaging>=24.2.0, but you have packaging 22.0 which is incompatible.\n",
            "chex 0.1.89 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "chex 0.1.89 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.9.3 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "pydantic-core 2.33.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "google-genai 1.15.0 requires typing-extensions<5.0.0,>=4.11.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.14.1 which is incompatible.\n",
            "sphinx 8.2.3 requires packaging>=23.0, but you have packaging 22.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, but you have scipy 1.9.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
            "albumentations 2.0.6 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n",
            "typing-inspection 0.4.0 requires typing-extensions>=4.12.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.9.3 which is incompatible.\n",
            "typeguard 4.4.2 requires typing_extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "optax 0.2.4 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "optax 0.2.4 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "openai 1.78.1 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.14 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 22.0 which is incompatible.\n",
            "langchain-core 0.3.59 requires packaging<25,>=23.2, but you have packaging 22.0 which is incompatible.\n",
            "langchain-core 0.3.59 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrs-23.1.0 dm-tree-0.1.8 dp-accounting-0.4.3 google-auth-oauthlib-1.0.0 google-vizier-0.1.11 googleapis-common-protos-1.61.0 grpcio-tools-1.62.3 jax-0.4.14 jaxlib-0.4.14 keras-2.14.0 numpy-1.25.2 packaging-22.0 portpicker-1.6.0 scipy-1.9.3 sqlalchemy-1.4.20 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-estimator-2.14.0 tensorflow-federated-0.81.0 tensorflow-model-optimization-0.7.5 tensorflow-privacy-0.9.0 tensorflow-probability-0.22.1 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "jax",
                  "jaxlib",
                  "keras",
                  "numpy",
                  "portpicker",
                  "tensorboard",
                  "tensorflow"
                ]
              },
              "id": "5035abb3dfc44be3ade81932a7202d9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-privacy==0.9.0 in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: absl-py==1.*,>=1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (1.4.0)\n",
            "Requirement already satisfied: dm-tree==0.1.8 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (0.1.8)\n",
            "Requirement already satisfied: dp-accounting==0.4.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (0.4.3)\n",
            "Requirement already satisfied: numpy~=1.21 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (1.25.2)\n",
            "Requirement already satisfied: packaging~=22.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (22.0)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (1.6.1)\n",
            "Requirement already satisfied: scipy~=1.9 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (1.9.3)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (2.14.0)\n",
            "Requirement already satisfied: tensorflow-probability~=0.22.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (0.22.1)\n",
            "Requirement already satisfied: tensorflow~=2.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (2.14.1)\n",
            "Requirement already satisfied: attrs>=22 in /usr/local/lib/python3.11/dist-packages (from dp-accounting==0.4.3->tensorflow-privacy==0.9.0) (23.1.0)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.11/dist-packages (from dp-accounting==0.4.3->tensorflow-privacy==0.9.0) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0) (3.6.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (4.25.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (2.14.1)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.4->tensorflow-privacy==0.9.0) (2.14.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0) (3.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow~=2.4->tensorflow-privacy==0.9.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow~=2.4->tensorflow-privacy==0.9.0) (3.2.2)\n",
            "^C\n",
            "^C\n",
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5gJVBJWLpy1",
        "outputId": "6199c8b5-caba-4d9d-f7d3-5bda93f1a866"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /usr/local/lib/python3.11/dist-packages/jax_plugins"
      ],
      "metadata": {
        "id": "ByDwyo9EOOYb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"TFF version:\", tff.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f8zXU4R6JmA",
        "outputId": "0b1bfad4-c3f3-46f2-b403-fdb23e6a5466"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:Jax plugin configuration error: Plugin module jax_plugins.xla_cuda12 does not exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.14.1\n",
            "TFF version: 0.81.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "80QzDcra3UpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71c6d70-1bbb-49da-a715-3b3314be5219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-43537eeb4cce>:30: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_train['labels'] = df_train['labels'].replace(attack_mapping)\n",
            "<ipython-input-4-43537eeb4cce>:31: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_test['labels'] = df_test['labels'].replace(attack_mapping)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in train set: [0 1 3 2 4]\n",
            "Unique labels in test set: [0 2 1 3 4]\n",
            "Train dataset shape: (125973, 40) (125973,)\n",
            "Test dataset shape: (22544, 40) (22544,)\n"
          ]
        }
      ],
      "source": [
        "#cell 1\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access data files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load datasets\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kdd_train.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kdd_test.csv')\n",
        "\n",
        "# Define label mapping for attack categories (including all labels from train and test sets)\n",
        "attack_mapping = {\n",
        "    'normal': 0, 'neptune': 1, 'land': 1, 'back': 1, 'teardrop': 1, 'pod': 1, 'smurf': 1,\n",
        "    'ipsweep': 2, 'nmap': 2, 'portsweep': 2, 'satan': 2,\n",
        "    'mailbomb': 1, 'apache2': 1, 'processtable': 1,  # Missing DoS labels in test set\n",
        "    'phf': 3, 'multihop': 3, 'warezclient': 3, 'warezmaster': 3, 'spy': 3, 'ftp_write': 3,\n",
        "    'guess_passwd': 3, 'imap': 3,\n",
        "    'buffer_overflow': 4, 'loadmodule': 4, 'perl': 4, 'rootkit': 4,\n",
        "    # Ensure all test labels are included\n",
        "    'mscan': 2, 'saint': 2, 'snmpgetattack': 3, 'snmpguess': 3, 'xlock': 3, 'xsnoop': 3,\n",
        "    'httptunnel': 3, 'ps': 4, 'xterm': 4,\n",
        "    'sendmail': 3, 'named': 3  # Missing labels in test set\n",
        "}\n",
        "\n",
        "# Apply the label mapping\n",
        "df_train['labels'] = df_train['labels'].replace(attack_mapping)\n",
        "df_test['labels'] = df_test['labels'].replace(attack_mapping)\n",
        "\n",
        "# Verify the unique labels after mapping\n",
        "print(\"Unique labels in train set:\", df_train['labels'].unique())\n",
        "print(\"Unique labels in test set:\", df_test['labels'].unique())\n",
        "\n",
        "# Dropping the irrelevant column 'num_outbound_cmds'\n",
        "df_train = df_train.drop('num_outbound_cmds', axis=1)\n",
        "df_test = df_test.drop('num_outbound_cmds', axis=1)\n",
        "\n",
        "# Encoding categorical columns: 'protocol_type', 'service', 'flag'\n",
        "categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df_train[col] = le.fit_transform(df_train[col])\n",
        "    df_test[col] = le.transform(df_test[col])  # Important: use transform for test set, not fit_transform\n",
        "\n",
        "# Scaling numerical columns\n",
        "numerical_columns = [\n",
        "    'duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'same_srv_rate',\n",
        "    'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
        "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_srv_diff_host_rate', 'dst_host_rerror_rate',\n",
        "    'dst_host_srv_rerror_rate', 'hot', 'num_compromised', 'num_root'\n",
        "]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_train[numerical_columns] = scaler.fit_transform(df_train[numerical_columns])\n",
        "df_test[numerical_columns] = scaler.transform(df_test[numerical_columns])\n",
        "\n",
        "# Convert to NumPy arrays and enforce correct types for TensorFlow\n",
        "X_train = np.array(df_train.drop('labels', axis=1)).astype(np.float32)\n",
        "y_train = np.array(df_train['labels']).astype(np.int32)\n",
        "\n",
        "X_test = np.array(df_test.drop('labels', axis=1)).astype(np.float32)\n",
        "y_test = np.array(df_test['labels']).astype(np.int32)\n",
        "\n",
        "# Convert to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
        "\n",
        "# Check dataset shapes\n",
        "print(\"Train dataset shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test dataset shape:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Cell2: Create Non-IID Partitions with Dirichlet Label Skew (Modified Version)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "NUM_CLIENTS = 10\n",
        "NUM_CLASSES = 5  # Based on your 5 attack categories (0-4)\n",
        "ALPHA = 0.5      # Dirichlet concentration parameter (α=0.5 for moderate skew)\n",
        "SEED = 42        # For reproducibility\n",
        "MIN_SAMPLES_PER_CLIENT = 100  # Ensure clients have sufficient data\n",
        "\n",
        "np.random.seed(SEED)  # Fix randomness for reproducibility\n",
        "\n",
        "# Step 1: Generate client-specific label distributions using Dirichlet\n",
        "client_label_probs = np.random.dirichlet([ALPHA]*NUM_CLASSES, size=NUM_CLIENTS)\n",
        "\n",
        "# Initialize list to store partitions\n",
        "data_partitions = []\n",
        "\n",
        "# Create partitions using Dirichlet distributions\n",
        "for client_id in range(NUM_CLIENTS):\n",
        "    partition = pd.DataFrame()\n",
        "    client_probs = client_label_probs[client_id]  # Probability vector for this client\n",
        "\n",
        "    # For each class, sample data proportionally to Dirichlet probabilities\n",
        "    for label in range(NUM_CLASSES):\n",
        "        class_data = df_train[df_train['labels'] == label]\n",
        "        if len(class_data) == 0:\n",
        "            continue  # Skip empty classes\n",
        "\n",
        "        # Calculate number of samples for this class\n",
        "        num_samples = max(\n",
        "            MIN_SAMPLES_PER_CLIENT // NUM_CLASSES,  # Minimum guarantee\n",
        "            int(len(class_data) * client_probs[label])  # Dirichlet proportion\n",
        "        )\n",
        "\n",
        "        # Sample without replacement\n",
        "        sampled_data = class_data.sample(n=num_samples, replace=False, random_state=SEED+client_id)\n",
        "        partition = pd.concat([partition, sampled_data])\n",
        "\n",
        "    # Final checks\n",
        "    if len(partition) == 0:\n",
        "        raise ValueError(f\"Client {client_id} has no data!\")\n",
        "\n",
        "    # Shuffle and store\n",
        "    data_partitions.append(\n",
        "        partition.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    # Print verification\n",
        "    print(f\"\\nClient {client_id+1} Label Distribution (Dirichlet α={ALPHA}):\")\n",
        "    print(partition['labels'].value_counts().sort_index())\n",
        "    print(f\"Target distribution: {np.round(client_probs, 2)}\")\n",
        "\n",
        "print(\"\\nSuccessfully created Dirichlet-based non-IID partitions!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rKUQqdCvKrZ",
        "outputId": "a5dbe4d4-fedb-4fd1-bcc8-f27b11d00f19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Client 1 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0     7854\n",
            "1    25164\n",
            "2      235\n",
            "3       20\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.12 0.55 0.02 0.   0.31]\n",
            "\n",
            "Client 2 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0       20\n",
            "1    35730\n",
            "2      273\n",
            "3       65\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.   0.78 0.02 0.07 0.13]\n",
            "\n",
            "Client 3 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    23786\n",
            "1     3526\n",
            "2     2181\n",
            "3       35\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.35 0.08 0.19 0.04 0.35]\n",
            "\n",
            "Client 4 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0       70\n",
            "1    38573\n",
            "2      268\n",
            "3      131\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.   0.84 0.02 0.13 0.  ]\n",
            "\n",
            "Client 5 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0     20\n",
            "1    754\n",
            "2    277\n",
            "3     73\n",
            "4     46\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.   0.02 0.02 0.07 0.89]\n",
            "\n",
            "Client 6 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    55215\n",
            "1     5767\n",
            "2       30\n",
            "3       20\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.82 0.13 0.   0.   0.05]\n",
            "\n",
            "Client 7 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    36580\n",
            "1     1835\n",
            "2      117\n",
            "3       20\n",
            "4       21\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.54 0.04 0.01 0.   0.4 ]\n",
            "\n",
            "Client 8 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0      20\n",
            "1    9662\n",
            "2    3309\n",
            "3     468\n",
            "4      20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.   0.21 0.28 0.47 0.03]\n",
            "\n",
            "Client 9 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    11667\n",
            "1    18907\n",
            "2       44\n",
            "3      199\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.17 0.41 0.   0.2  0.21]\n",
            "\n",
            "Client 10 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    8455\n",
            "1      20\n",
            "2      20\n",
            "3      45\n",
            "4      43\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.13 0.   0.   0.05 0.83]\n",
            "\n",
            "Successfully created Dirichlet-based non-IID partitions!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Cell3: Create Label-Skew Partitions\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "NUM_CLIENTS = 10\n",
        "CLASS_MAPPING = {'Benign': 0, 'DoS': 1, 'Probe': 2, 'U2R': 3, 'R2L': 4}\n",
        "MIN_SAMPLES_PER_CLASS = 50  # Prevent class starvation\n",
        "\n",
        "# Label distribution per client (matches your paper's setup)\n",
        "client_class_map = {\n",
        "    0: ['Benign', 'DoS'],\n",
        "    1: ['Benign', 'Probe'],\n",
        "    2: ['Benign', 'U2R'],\n",
        "    3: ['Benign', 'R2L'],\n",
        "    4: ['DoS', 'Probe'],\n",
        "    5: ['DoS', 'U2R'],\n",
        "    6: ['DoS', 'R2L'],\n",
        "    7: ['Probe', 'U2R'],\n",
        "    8: ['Probe', 'R2L'],\n",
        "    9: ['U2R', 'R2L']\n",
        "}\n",
        "\n",
        "data_partitions = []\n",
        "for client_id in range(NUM_CLIENTS):\n",
        "    client_partition = pd.DataFrame()\n",
        "    classes = client_class_map[client_id]\n",
        "\n",
        "    for class_name in classes:\n",
        "        label = CLASS_MAPPING[class_name]\n",
        "        class_data = df_train[df_train['labels'] == label]\n",
        "\n",
        "        # Dynamic sampling with minimum guarantee\n",
        "        proportion = np.random.uniform(0.1, 0.4)  # 10-40% of class data\n",
        "        num_samples = max(MIN_SAMPLES_PER_CLASS, int(len(class_data) * proportion))\n",
        "\n",
        "        client_partition = pd.concat([\n",
        "            client_partition,\n",
        "            class_data.sample(n=num_samples, random_state=42+client_id)\n",
        "        ])\n",
        "\n",
        "    # Shuffle and store\n",
        "    data_partitions.append(\n",
        "        client_partition.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    # Verification\n",
        "    print(f\"\\nClient {client_id+1} Distribution:\")\n",
        "    print(client_partition['labels'].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKxCZ-BWvVou",
        "outputId": "4edf286a-0d1c-4444-d835-0b23fcd62b63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Client 1 Distribution:\n",
            "labels\n",
            "0    15025\n",
            "1    15002\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 2 Distribution:\n",
            "labels\n",
            "0    11356\n",
            "2     1434\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 3 Distribution:\n",
            "labels\n",
            "0    12588\n",
            "3      147\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 4 Distribution:\n",
            "labels\n",
            "0    25516\n",
            "4       50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 5 Distribution:\n",
            "labels\n",
            "1    13319\n",
            "2     4212\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 6 Distribution:\n",
            "labels\n",
            "1    15665\n",
            "3      155\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 7 Distribution:\n",
            "labels\n",
            "1    16890\n",
            "4       50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 8 Distribution:\n",
            "labels\n",
            "2    3989\n",
            "3     366\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 9 Distribution:\n",
            "labels\n",
            "2    2277\n",
            "4      50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 10 Distribution:\n",
            "labels\n",
            "3    167\n",
            "4     50\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Cell4 : Create TensorFlow Datasets (Final Corrected Version)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Configuration\n",
        "batch_size = 32\n",
        "SEED = 42  # For reproducible shuffling\n",
        "\n",
        "train_datasets = []\n",
        "val_datasets = []\n",
        "\n",
        "for client_id, partition in enumerate(data_partitions):\n",
        "    # ========== Exact 90/10 Split ==========\n",
        "    total_samples = len(partition)\n",
        "    train_samples = (total_samples // 10) * 9  # Exact 90%\n",
        "    val_samples = total_samples - train_samples  # Exact 10%\n",
        "\n",
        "    # Shuffle with client-specific seed\n",
        "    shuffled_partition = partition.sample(frac=1, random_state=SEED+client_id).reset_index(drop=True)\n",
        "\n",
        "    # Split into train/val\n",
        "    train_part = shuffled_partition.iloc[:train_samples]\n",
        "    val_part = shuffled_partition.iloc[train_samples:]\n",
        "\n",
        "    # ========== Feature/Label Conversion ==========\n",
        "    # Training data\n",
        "    train_features = train_part.drop(columns=['labels']).values.astype(np.float32)\n",
        "    train_labels = train_part['labels'].values.astype(np.int32)\n",
        "\n",
        "    # Validation data\n",
        "    val_features = val_part.drop(columns=['labels']).values.astype(np.float32)\n",
        "    val_labels = val_part['labels'].values.astype(np.int32)\n",
        "\n",
        "    # ========== Dataset Creation ==========\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (train_features, train_labels)\n",
        "    ).batch(batch_size)\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (val_features, val_labels)\n",
        "    ).batch(batch_size)\n",
        "\n",
        "    # Store datasets\n",
        "    train_datasets.append(train_dataset)\n",
        "    val_datasets.append(val_dataset)\n",
        "\n",
        "    # ========== Verification ==========\n",
        "    print(f\"Client {client_id+1}:\")\n",
        "    print(f\"  Train: {len(train_part)} samples | Classes: {np.unique(train_labels)}\")\n",
        "    print(f\"  Val: {len(val_part)} samples | Classes: {np.unique(val_labels)}\\n\")\n",
        "\n",
        "# ========== Test Dataset ==========\n",
        "test_features = df_test.drop(columns=['labels']).values.astype(np.float32)\n",
        "test_labels = df_test['labels'].values.astype(np.int32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_features, test_labels)\n",
        ").batch(batch_size)\n",
        "\n",
        "print(\"=== Final Verification ===\")\n",
        "print(f\"Total training clients: {len(train_datasets)}\")\n",
        "print(f\"Test samples: {len(test_labels)}\")\n",
        "print(f\"Test features shape: {test_features.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VISmOyIqvW74",
        "outputId": "535e8420-97f9-492b-841b-e8e6f79abbba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 1:\n",
            "  Train: 27018 samples | Classes: [0 1]\n",
            "  Val: 3009 samples | Classes: [0 1]\n",
            "\n",
            "Client 2:\n",
            "  Train: 11511 samples | Classes: [0 2]\n",
            "  Val: 1279 samples | Classes: [0 2]\n",
            "\n",
            "Client 3:\n",
            "  Train: 11457 samples | Classes: [0 3]\n",
            "  Val: 1278 samples | Classes: [0 3]\n",
            "\n",
            "Client 4:\n",
            "  Train: 23004 samples | Classes: [0 4]\n",
            "  Val: 2562 samples | Classes: [0 4]\n",
            "\n",
            "Client 5:\n",
            "  Train: 15777 samples | Classes: [1 2]\n",
            "  Val: 1754 samples | Classes: [1 2]\n",
            "\n",
            "Client 6:\n",
            "  Train: 14238 samples | Classes: [1 3]\n",
            "  Val: 1582 samples | Classes: [1 3]\n",
            "\n",
            "Client 7:\n",
            "  Train: 15246 samples | Classes: [1 4]\n",
            "  Val: 1694 samples | Classes: [1 4]\n",
            "\n",
            "Client 8:\n",
            "  Train: 3915 samples | Classes: [2 3]\n",
            "  Val: 440 samples | Classes: [2 3]\n",
            "\n",
            "Client 9:\n",
            "  Train: 2088 samples | Classes: [2 4]\n",
            "  Val: 239 samples | Classes: [2 4]\n",
            "\n",
            "Client 10:\n",
            "  Train: 189 samples | Classes: [3 4]\n",
            "  Val: 28 samples | Classes: [3 4]\n",
            "\n",
            "=== Final Verification ===\n",
            "Total training clients: 10\n",
            "Test samples: 22544\n",
            "Test features shape: (22544, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Cell5: Centralized Training (Label Skew Version)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def centralized_training(seed=42):\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "\n",
        "    # 1. Combine all client partitions (NEW FOR LABEL SKEW)\n",
        "    full_train = pd.concat(data_partitions).sample(frac=1, random_state=seed)\n",
        "    full_train_features = full_train.drop('labels', axis=1).values.astype(np.float32)\n",
        "    full_train_labels = full_train['labels'].values.astype(np.int32)\n",
        "\n",
        "    # 2. Create model (same architecture as FL)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # 3. Training with metrics tracking\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(\n",
        "        full_train_features, full_train_labels,\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        validation_data=(test_features, test_labels),  # Use your existing test data\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # 4. Final evaluation\n",
        "    y_pred = np.argmax(model.predict(test_features), axis=1)\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'train_loss': history.history['loss'],\n",
        "        'val_loss': history.history['val_loss'],\n",
        "        'test_accuracy': history.history['val_accuracy'][-1],\n",
        "        'test_precision': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'test_recall': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'test_f1': f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    }\n",
        "\n",
        "# Run with multiple seeds\n",
        "results_cl = [centralized_training(seed=s) for s in [42, 123, 456]]\n",
        "\n",
        "# Generate report\n",
        "report_cl = pd.DataFrame(results_cl)\n",
        "print(\"\\nCentralized Training Results (Label Skew Scenario):\")\n",
        "display(report_cl[['seed', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']])"
      ],
      "metadata": {
        "id": "06lTg3OVvh8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Cell6: Federated Learning with Statistical Significance\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import collections\n",
        "from scipy import stats\n",
        "\n",
        "# ======================\n",
        "# 1. Data Preprocessing\n",
        "# ======================\n",
        "\n",
        "def preprocess(dataset):\n",
        "    def batch_format_fn(features, labels):\n",
        "        return collections.OrderedDict(\n",
        "            x=tf.reshape(features, [-1, 40]),  # Flatten features\n",
        "            y=tf.reshape(labels, [-1])  # Reshape labels\n",
        "        )\n",
        "    padded_shapes = ([None, 40], [None])\n",
        "    return dataset.padded_batch(32, padded_shapes=padded_shapes).map(batch_format_fn).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# ======================\n",
        "# 2. Core FL Functions\n",
        "# ======================\n",
        "\n",
        "def create_keras_model():\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "def make_federated_data(client_data, client_ids):\n",
        "    \"\"\"Global function to create federated datasets\"\"\"\n",
        "    return [\n",
        "        preprocess(client_data[i])\n",
        "        for i in client_ids\n",
        "        if len(list(client_data[i])) > 0  # Filter empty datasets\n",
        "    ]\n",
        "\n",
        "def run_fl_trial(seed=42, num_rounds=30):\n",
        "    \"\"\"Run complete FL pipeline with specified seed\"\"\"\n",
        "    # Set all seeds\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Model function\n",
        "    def model_fn():\n",
        "        return tff.learning.models.from_keras_model(\n",
        "            create_keras_model(),\n",
        "            input_spec=federated_train_data[0].element_spec,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "        )\n",
        "\n",
        "    # Build training process\n",
        "    training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn,\n",
        "        client_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.001),\n",
        "        server_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.01)\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    state = training_process.initialize()\n",
        "    for _ in range(num_rounds):\n",
        "        state = training_process.next(state, federated_train_data).state\n",
        "\n",
        "    # Evaluation\n",
        "    eval_model = create_keras_model()\n",
        "    eval_model.set_weights(list(training_process.get_model_weights(state).trainable))\n",
        "    y_pred = np.argmax(eval_model.predict(test_features), axis=1)\n",
        "\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'f1': f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    }\n",
        "\n",
        "# ======================\n",
        "# 3. Execution & Analysis\n",
        "# ======================\n",
        "\n",
        "# Configuration\n",
        "NUM_CLIENTS = 10\n",
        "SEEDS = [42, 123, 456]\n",
        "\n",
        "# Create federated data (ensure train_datasets exists)\n",
        "federated_train_data = make_federated_data(train_datasets, list(range(NUM_CLIENTS)))\n",
        "\n",
        "# Run trials\n",
        "fl_results = [run_fl_trial(seed=s) for s in SEEDS]\n",
        "\n",
        "# Statistical comparison with centralized results (assuming results_cl exists)\n",
        "def print_stat_comparison(cl_results, fl_results):\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        cl_values = [r[f'test_{metric}'] for r in cl_results]\n",
        "        fl_values = [r[metric] for r in fl_results]\n",
        "        t_stat, p_value = stats.ttest_ind(cl_values, fl_values)\n",
        "\n",
        "        print(f\"\\n{metric.upper():<10} CL: {np.mean(cl_values):.4f} ± {np.std(cl_values):.4f}\")\n",
        "        print(f\"{'FL:':<10} {np.mean(fl_values):.4f} ± {np.std(fl_values):.4f}\")\n",
        "        print(f\"{'p-value:':<10} {p_value:.4e}{'*' if p_value < 0.05 else ''}\")\n",
        "\n",
        "print(\"\\n=== Statistical Significance ===\")\n",
        "print_stat_comparison(results_cl, fl_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXWIgedTwE4_",
        "outputId": "d0688b52-6e8f-4442-b16e-bcc411559a95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "=== Statistical Significance ===\n",
            "\n",
            "ACCURACY   CL: 0.9294 ± 0.0036\n",
            "FL:        0.8395 ± 0.0114\n",
            "p-value:   4.3965e-04*\n",
            "\n",
            "PRECISION  CL: 0.9069 ± 0.0399\n",
            "FL:        0.4738 ± 0.0906\n",
            "p-value:   3.4658e-03*\n",
            "\n",
            "RECALL     CL: 0.6959 ± 0.0223\n",
            "FL:        0.4063 ± 0.0186\n",
            "p-value:   1.4659e-04*\n",
            "\n",
            "F1         CL: 0.7386 ± 0.0223\n",
            "FL:        0.3991 ± 0.0293\n",
            "p-value:   1.9983e-04*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "unique_labels, counts = np.unique(y_test, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Class {label}: {count} samples ({count/len(y_test):.1%})\")"
      ],
      "metadata": {
        "id": "Aw0fvuKdElec",
        "outputId": "fecd3062-a573-4aaf-f6ed-78bc7cb92ae6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 11245 samples (49.9%)\n",
            "Class 1: 8095 samples (35.9%)\n",
            "Class 2: 2157 samples (9.6%)\n",
            "Class 3: 1009 samples (4.5%)\n",
            "Class 4: 38 samples (0.2%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Cell5: Enhanced Centralized Training with Full Metrics\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def centralized_training(seed=42, epochs=30):\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "\n",
        "    # 1. Combine all client data\n",
        "    full_train = pd.concat(data_partitions).sample(frac=1, random_state=seed)\n",
        "    X_train = full_train.drop('labels', axis=1).values.astype(np.float32)\n",
        "    y_train = full_train['labels'].values.astype(np.int32)\n",
        "\n",
        "    # 2. Model definition\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # 3. Custom callback for metrics\n",
        "    class CLMetrics(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            # Test set evaluation\n",
        "            y_pred = np.argmax(model.predict(test_features), axis=1)\n",
        "            logs['test_precision'] = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "            logs['test_recall'] = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "            logs['test_f1'] = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "            # Interval reporting\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                print(f\"\\nEpoch {epoch+1}/{epochs}:\")\n",
        "                print(f\"Train Loss: {logs['loss']:.4f} | Test Loss: {logs['val_loss']:.4f}\")\n",
        "                print(f\"Accuracy: {logs['val_accuracy']:.4f} | F1: {logs['test_f1']:.4f}\")\n",
        "\n",
        "    # 4. Training\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        validation_data=(test_features, test_labels),\n",
        "        callbacks=[CLMetrics()],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # 5. Calculate RMSE\n",
        "    train_rmse = np.sqrt(np.mean(np.square(history.history['loss'])))\n",
        "    test_rmse = np.sqrt(np.mean(np.square(history.history['val_loss'])))\n",
        "\n",
        "    return {\n",
        "        'train_loss': history.history['loss'],\n",
        "        'test_loss': history.history['val_loss'],\n",
        "        'test_accuracy': history.history['val_accuracy'],\n",
        "        'test_precision': [history.history[f'test_precision'][i] for i in range(epochs)],\n",
        "        'test_recall': [history.history[f'test_recall'][i] for i in range(epochs)],\n",
        "        'test_f1': [history.history[f'test_f1'][i] for i in range(epochs)],\n",
        "        'train_rmse': train_rmse,\n",
        "        'test_rmse': test_rmse\n",
        "    }\n",
        "\n",
        "# Run centralized training\n",
        "cl_results = centralized_training()\n",
        "print(f\"\\nFinal RMSE - Train: {cl_results['train_rmse']:.4f}, Test: {cl_results['test_rmse']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_CkQF3mO9AN",
        "outputId": "08de206d-f0d7-4d87-e00a-32045b79f0ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 2ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 5/30:\n",
            "Train Loss: 0.0266 | Test Loss: 0.6592\n",
            "Accuracy: 0.9186 | F1: 0.7217\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "\n",
            "Epoch 10/30:\n",
            "Train Loss: 0.0188 | Test Loss: 0.7648\n",
            "Accuracy: 0.9239 | F1: 0.7195\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 15/30:\n",
            "Train Loss: 0.0147 | Test Loss: 0.6757\n",
            "Accuracy: 0.9233 | F1: 0.7325\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "\n",
            "Epoch 20/30:\n",
            "Train Loss: 0.0130 | Test Loss: 0.9732\n",
            "Accuracy: 0.9259 | F1: 0.7062\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "\n",
            "Epoch 25/30:\n",
            "Train Loss: 0.0119 | Test Loss: 0.9634\n",
            "Accuracy: 0.9283 | F1: 0.7440\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "\n",
            "Epoch 30/30:\n",
            "Train Loss: 0.0115 | Test Loss: 1.0644\n",
            "Accuracy: 0.9268 | F1: 0.7336\n",
            "\n",
            "Final RMSE - Train: 0.0270, Test: 0.8272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Cell6: Federated Learning with Statistical Significance (Working Version)\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import collections\n",
        "from scipy import stats\n",
        "\n",
        "# ======================\n",
        "# 1. Data Preprocessing\n",
        "# ======================\n",
        "\n",
        "def preprocess(dataset):\n",
        "    def batch_format_fn(features, labels):\n",
        "        return collections.OrderedDict(\n",
        "            x=tf.reshape(features, [-1, 40]),  # Flatten features\n",
        "            y=tf.reshape(labels, [-1])  # Reshape labels\n",
        "        )\n",
        "    padded_shapes = ([None, 40], [None])\n",
        "    return dataset.padded_batch(32, padded_shapes=padded_shapes).map(batch_format_fn).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 2. Core FL Functions\n",
        "# ======================\n",
        "\n",
        "def create_keras_model():\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "def make_federated_data(client_data, client_ids):\n",
        "    \"\"\"Create federated datasets from client data\"\"\"\n",
        "    return [\n",
        "        preprocess(client_data[i])\n",
        "        for i in client_ids\n",
        "        if len(list(client_data[i])) > 0  # Filter empty datasets\n",
        "    ]\n",
        "\n",
        "# ======================\n",
        "# 3. Enhanced FL Training\n",
        "# ======================\n",
        "\n",
        "def run_fl_trial(seed=42, num_rounds=30):\n",
        "    \"\"\"Run complete FL pipeline with metrics tracking\"\"\"\n",
        "    # Set all seeds\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Model function\n",
        "    def model_fn():\n",
        "        return tff.learning.models.from_keras_model(\n",
        "            create_keras_model(),\n",
        "            input_spec=federated_train_data[0].element_spec,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "        )\n",
        "\n",
        "    # Build training process\n",
        "    training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn,\n",
        "        client_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.001),\n",
        "        server_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.01)\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    state = training_process.initialize()\n",
        "    train_losses = []\n",
        "\n",
        "    for _ in range(num_rounds):\n",
        "        result = training_process.next(state, federated_train_data)\n",
        "        state = result.state\n",
        "        train_losses.append(result.metrics['client_work']['train']['loss'])\n",
        "\n",
        "    # Final evaluation\n",
        "    eval_model = create_keras_model()\n",
        "    eval_model.set_weights(training_process.get_model_weights(state).trainable)\n",
        "    y_pred = np.argmax(eval_model.predict(test_features), axis=1)\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    test_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_test, eval_model.predict(test_features)\n",
        "    ).numpy().mean()\n",
        "\n",
        "    return {\n",
        "        'train_loss': train_losses,\n",
        "        'test_loss': test_loss,\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'f1': f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    }\n",
        "\n",
        "# ======================\n",
        "# 4. Execution & Analysis\n",
        "# ======================\n",
        "\n",
        "# Configuration\n",
        "NUM_CLIENTS = 10\n",
        "SEEDS = [42, 123, 456]\n",
        "\n",
        "# Prepare federated data\n",
        "federated_train_data = make_federated_data(train_datasets, list(range(NUM_CLIENTS)))\n",
        "\n",
        "# Run multiple trials\n",
        "fl_results = [run_fl_trial(seed=s) for s in SEEDS]\n",
        "\n",
        "# Statistical comparison function\n",
        "def print_stat_comparison(cl_results, fl_results):\n",
        "    print(\"\\n=== Statistical Significance ===\")\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        cl_values = [r[f'test_{metric}'] for r in cl_results]\n",
        "        fl_values = [r[metric] for r in fl_results]\n",
        "        t_stat, p_value = stats.ttest_ind(cl_values, fl_values)\n",
        "\n",
        "        print(f\"\\n{metric.upper():<10} CL: {np.mean(cl_values):.4f} ± {np.std(cl_values):.4f}\")\n",
        "        print(f\"{'FL:':<10} {np.mean(fl_values):.4f} ± {np.std(fl_values):.4f}\")\n",
        "        print(f\"{'p-value:':<10} {p_value:.4e}{'*' if p_value < 0.05 else ''}\")\n",
        "\n",
        "# Generate report\n",
        "print_stat_comparison(results_cl, fl_results)\n",
        "\n",
        "# Additional metrics visualization\n",
        "print(\"\\nTraining Loss Curve:\")\n",
        "plt.plot(fl_results[0]['train_loss'])\n",
        "plt.xlabel('Communication Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "-bUhuasnPDz4",
        "outputId": "73d49204-b98d-4be1-e366-8d1a1a66f8d1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 2s 3ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "\n",
            "=== Statistical Significance ===\n",
            "\n",
            "ACCURACY   CL: 0.9276 ± 0.0012\n",
            "FL:        0.8405 ± 0.0129\n",
            "p-value:   6.7194e-04*\n",
            "\n",
            "PRECISION  CL: 0.9017 ± 0.0400\n",
            "FL:        0.4762 ± 0.0926\n",
            "p-value:   3.9688e-03*\n",
            "\n",
            "RECALL     CL: 0.6916 ± 0.0065\n",
            "FL:        0.4118 ± 0.0264\n",
            "p-value:   1.2920e-04*\n",
            "\n",
            "F1         CL: 0.7324 ± 0.0125\n",
            "FL:        0.4071 ± 0.0411\n",
            "p-value:   4.3245e-04*\n",
            "\n",
            "Training Loss Curve:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# codes for all metrics (new)"
      ],
      "metadata": {
        "id": "jZAhx3sGML7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Cell5: Centralized Training (Full Metrics + Reporting)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def centralized_training(seed=42, epochs=30):\n",
        "    # Set seeds\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # 1. Prepare data\n",
        "    full_train = pd.concat(data_partitions).sample(frac=1, random_state=seed)\n",
        "    X_train = full_train.drop('labels', axis=1).values.astype(np.float32)\n",
        "    y_train = full_train['labels'].values.astype(np.int32)\n",
        "\n",
        "    # 2. Model definition\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # 3. Model size calculation\n",
        "    model_size = sum([tf.size(w).numpy() for w in model.weights]) * 4 / (1024**2)  # MB\n",
        "\n",
        "    # 4. Training with metrics callback\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    class PrintMetrics(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            if (epoch+1) % 5 == 0:\n",
        "                y_pred = np.argmax(model.predict(test_features), axis=1)\n",
        "                print(f\"\\nEpoch {epoch+1}:\")\n",
        "                print(f\"Train Loss: {logs['loss']:.4f} | Test Loss: {logs['val_loss']:.4f}\")\n",
        "                print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "                print(f\"F1-Score: {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        validation_data=(test_features, test_labels),\n",
        "        callbacks=[PrintMetrics()],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # 5. Final metrics\n",
        "    y_pred = np.argmax(model.predict(test_features), axis=1)\n",
        "    train_rmse = np.sqrt(np.mean(np.square(history.history['loss'])))\n",
        "    test_rmse = np.sqrt(np.mean(np.square(history.history['val_loss'])))\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'time': time.time()-start_time,\n",
        "        'model_size_mb': model_size,\n",
        "        'train_rmse': train_rmse,\n",
        "        'test_rmse': test_rmse,\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, average='macro'),\n",
        "        'recall': recall_score(y_test, y_pred, average='macro'),\n",
        "        'f1': f1_score(y_test, y_pred, average='macro')\n",
        "    }\n",
        "\n",
        "# Run with 3 seeds\n",
        "cl_results = [centralized_training(seed=s) for s in [42, 123, 456]]"
      ],
      "metadata": {
        "id": "vd7l4x_3MQm3",
        "outputId": "8559236b-cbb2-47bf-b233-459102f2557f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 5:\n",
            "Train Loss: 0.0260 | Test Loss: 0.7114\n",
            "Accuracy: 0.9142\n",
            "F1-Score: 0.7121\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "\n",
            "Epoch 10:\n",
            "Train Loss: 0.0190 | Test Loss: 0.7805\n",
            "Accuracy: 0.9269\n",
            "F1-Score: 0.7333\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 15:\n",
            "Train Loss: 0.0148 | Test Loss: 0.8244\n",
            "Accuracy: 0.9291\n",
            "F1-Score: 0.7439\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 20:\n",
            "Train Loss: 0.0129 | Test Loss: 1.0537\n",
            "Accuracy: 0.9299\n",
            "F1-Score: 0.7547\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 25:\n",
            "Train Loss: 0.0124 | Test Loss: 1.0186\n",
            "Accuracy: 0.9316\n",
            "F1-Score: 0.7400\n",
            "705/705 [==============================] - 2s 3ms/step\n",
            "\n",
            "Epoch 30:\n",
            "Train Loss: 0.0118 | Test Loss: 1.2363\n",
            "Accuracy: 0.9299\n",
            "F1-Score: 0.7289\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 5:\n",
            "Train Loss: 0.0276 | Test Loss: 0.6044\n",
            "Accuracy: 0.9191\n",
            "F1-Score: 0.7311\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "\n",
            "Epoch 10:\n",
            "Train Loss: 0.0186 | Test Loss: 0.6740\n",
            "Accuracy: 0.9185\n",
            "F1-Score: 0.7187\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 15:\n",
            "Train Loss: 0.0150 | Test Loss: 0.8479\n",
            "Accuracy: 0.9159\n",
            "F1-Score: 0.7014\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 20:\n",
            "Train Loss: 0.0138 | Test Loss: 0.7545\n",
            "Accuracy: 0.9269\n",
            "F1-Score: 0.7396\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "\n",
            "Epoch 25:\n",
            "Train Loss: 0.0121 | Test Loss: 0.9571\n",
            "Accuracy: 0.9239\n",
            "F1-Score: 0.7523\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 30:\n",
            "Train Loss: 0.0110 | Test Loss: 0.9728\n",
            "Accuracy: 0.9248\n",
            "F1-Score: 0.7175\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 5:\n",
            "Train Loss: 0.0267 | Test Loss: 0.6038\n",
            "Accuracy: 0.9136\n",
            "F1-Score: 0.7187\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "\n",
            "Epoch 10:\n",
            "Train Loss: 0.0195 | Test Loss: 0.6195\n",
            "Accuracy: 0.9278\n",
            "F1-Score: 0.7399\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 15:\n",
            "Train Loss: 0.0166 | Test Loss: 0.6362\n",
            "Accuracy: 0.9261\n",
            "F1-Score: 0.7659\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 20:\n",
            "Train Loss: 0.0138 | Test Loss: 0.7324\n",
            "Accuracy: 0.9284\n",
            "F1-Score: 0.7600\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 25:\n",
            "Train Loss: 0.0127 | Test Loss: 0.8260\n",
            "Accuracy: 0.9322\n",
            "F1-Score: 0.7448\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Epoch 30:\n",
            "Train Loss: 0.0117 | Test Loss: 0.8501\n",
            "Accuracy: 0.9335\n",
            "F1-Score: 0.7695\n",
            "705/705 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Cell6: Federated Learning (Modified Code 2 – Fixed & Including Required Metrics)\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import collections\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ======================\n",
        "# 1. Data Preprocessing\n",
        "# ======================\n",
        "\n",
        "def preprocess(dataset):\n",
        "    def batch_format_fn(features, labels):\n",
        "        return collections.OrderedDict(\n",
        "            x=tf.reshape(features, [-1, 40]),  # Match input shape (40 features)\n",
        "            y=tf.reshape(labels, [-1])\n",
        "        )\n",
        "    padded_shapes = ([None, 40], [None])\n",
        "    return (\n",
        "        dataset\n",
        "        .padded_batch(32, padded_shapes=padded_shapes)\n",
        "        .map(batch_format_fn)\n",
        "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "# ======================\n",
        "# 2. Model & Federated Data\n",
        "# ======================\n",
        "\n",
        "def create_keras_model():\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "def make_federated_data(client_data, client_ids):\n",
        "    return [\n",
        "        preprocess(client_data[i])\n",
        "        for i in client_ids\n",
        "        if len(list(client_data[i])) > 0  # Skip any empty client dataset\n",
        "    ]\n",
        "\n",
        "# ======================\n",
        "# 3. Federated Learning Trial\n",
        "# ======================\n",
        "\n",
        "def run_fl_trial(seed=42, num_rounds=30):\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Compute model size in MB\n",
        "    temp_model = create_keras_model()\n",
        "    model_size_bytes = sum([tf.size(w).numpy() for w in temp_model.weights]) * 4  # float32 → 4 bytes\n",
        "    model_size_mb = model_size_bytes / (1024 ** 2)\n",
        "\n",
        "    # Prepare federated data\n",
        "    federated_train_data = make_federated_data(train_datasets, list(range(NUM_CLIENTS)))\n",
        "\n",
        "    # Define model function for TFF (must create a *new* Keras model each time)\n",
        "    def model_fn():\n",
        "        keras_model = create_keras_model()\n",
        "        return tff.learning.models.from_keras_model(\n",
        "            keras_model,\n",
        "            input_spec=federated_train_data[0].element_spec,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "        )\n",
        "\n",
        "    # Build the Federated Averaging training process\n",
        "    training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn,\n",
        "        client_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.001),\n",
        "        server_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.01)\n",
        "    )\n",
        "\n",
        "    state = training_process.initialize()\n",
        "    train_losses = []\n",
        "    comm_cost_mb = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    for round_num in range(num_rounds):\n",
        "        result = training_process.next(state, federated_train_data)\n",
        "        state = result.state\n",
        "\n",
        "        # Capture the client training loss for this round\n",
        "        current_train_loss = result.metrics['client_work']['train']['loss']\n",
        "        train_losses.append(current_train_loss)\n",
        "\n",
        "        # Communication cost: one download + one upload per client per round\n",
        "        comm_cost_mb += model_size_mb * NUM_CLIENTS * 2\n",
        "\n",
        "        # Every 5 rounds, evaluate on the global test set and print metrics\n",
        "        if (round_num + 1) % 5 == 0:\n",
        "            # Instantiate a fresh model and load the latest federated weights\n",
        "            eval_model = create_keras_model()\n",
        "            eval_model.set_weights(\n",
        "                training_process.get_model_weights(state).trainable\n",
        "            )\n",
        "\n",
        "            # Compute predictions on the centralized test set\n",
        "            y_logits = eval_model.predict(test_features)\n",
        "            y_pred = np.argmax(y_logits, axis=1)\n",
        "            y_true = y_test\n",
        "\n",
        "            # Compute test loss manually\n",
        "            test_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "                y_true, y_logits\n",
        "            ).numpy().mean()\n",
        "\n",
        "            # Print round-wise metrics\n",
        "            print(f\"\\n--- Round {round_num+1}/{num_rounds} ---\")\n",
        "            print(f\"Train Loss (clients): {current_train_loss:.4f} | Test Loss: {test_loss:.4f}\")\n",
        "            print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f} | \"\n",
        "                  f\"Precision: {precision_score(y_true, y_pred, average='macro', zero_division=0):.4f} | \"\n",
        "                  f\"Recall: {recall_score(y_true, y_pred, average='macro', zero_division=0):.4f} | \"\n",
        "                  f\"F1-Score: {f1_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
        "\n",
        "    # Final evaluation after all rounds\n",
        "    eval_model = create_keras_model()\n",
        "    eval_model.set_weights(\n",
        "        training_process.get_model_weights(state).trainable\n",
        "    )\n",
        "    final_logits = eval_model.predict(test_features)\n",
        "    final_pred = np.argmax(final_logits, axis=1)\n",
        "    final_test_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_test, final_logits\n",
        "    ).numpy().mean()\n",
        "\n",
        "    return {\n",
        "        'train_time_sec': time.time() - start_time,\n",
        "        'model_size_mb': model_size_mb,\n",
        "        'comm_cost_mb': comm_cost_mb,\n",
        "        'train_losses': train_losses,\n",
        "        'final_test_loss': final_test_loss,\n",
        "        'accuracy': accuracy_score(y_test, final_pred),\n",
        "        'precision': precision_score(y_test, final_pred, average='macro', zero_division=0),\n",
        "        'recall': recall_score(y_test, final_pred, average='macro', zero_division=0),\n",
        "        'f1': f1_score(y_test, final_pred, average='macro', zero_division=0)\n",
        "    }\n",
        "\n",
        "# ======================\n",
        "# 4. Execution & Statistical Comparison\n",
        "# ======================\n",
        "\n",
        "# Configuration (must match the centralized setup)\n",
        "NUM_CLIENTS = 10\n",
        "SEEDS = [42, 123, 456]\n",
        "\n",
        "# Create federated datasets once before running trials\n",
        "federated_train_data = make_federated_data(train_datasets, list(range(NUM_CLIENTS)))\n",
        "\n",
        "# Run FL trials for each seed\n",
        "fl_results = [run_fl_trial(seed=s) for s in SEEDS]\n",
        "\n",
        "# Statistical comparison with centralized results (cl_results must already exist)\n",
        "from scipy import stats\n",
        "\n",
        "def print_comparison(cl_res, fl_res):\n",
        "    print(\"\\n=== CL vs FL Comparison ===\")\n",
        "    print(f\"{'Metric':<15} {'CL Mean±Std':<25} {'FL Mean±Std':<25} {'p-value':<10}\")\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        cl_vals = [r[f'test_{metric}'] for r in cl_res]\n",
        "        fl_vals = [r[metric] for r in fl_res]\n",
        "        t_stat, p_val = stats.ttest_ind(cl_vals, fl_vals)\n",
        "        print(f\"{metric.capitalize():<15} \"\n",
        "              f\"{np.mean(cl_vals):.4f}±{np.std(cl_vals):.4f} | \"\n",
        "              f\"{np.mean(fl_vals):.4f}±{np.std(fl_vals):.4f} | \"\n",
        "              f\"{p_val:.2e}{'*' if p_val < 0.05 else ''}\")\n",
        "\n",
        "# Call the comparison function\n",
        "print_comparison(cl_results, fl_results)\n"
      ],
      "metadata": {
        "id": "knDmhKzjUQta",
        "outputId": "bc58cd69-ba3d-40b1-b415-d03eefbd9bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 5/30 ---\n",
            "Train Loss (clients): 0.5390 | Test Loss: 1.5603\n",
            "Accuracy: 0.7190 | Precision: 0.2917 | Recall: 0.3403 | F1-Score: 0.3092\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 10/30 ---\n",
            "Train Loss (clients): 0.4025 | Test Loss: 1.5751\n",
            "Accuracy: 0.8046 | Precision: 0.3309 | Recall: 0.3716 | F1-Score: 0.3481\n",
            "705/705 [==============================] - 2s 3ms/step\n",
            "\n",
            "--- Round 15/30 ---\n",
            "Train Loss (clients): 0.2621 | Test Loss: 1.4434\n",
            "Accuracy: 0.7308 | Precision: 0.2988 | Recall: 0.3474 | F1-Score: 0.3146\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 20/30 ---\n",
            "Train Loss (clients): 0.4005 | Test Loss: 1.7424\n",
            "Accuracy: 0.7871 | Precision: 0.3377 | Recall: 0.3609 | F1-Score: 0.3426\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 25/30 ---\n",
            "Train Loss (clients): 0.2505 | Test Loss: 1.3001\n",
            "Accuracy: 0.7988 | Precision: 0.4691 | Recall: 0.3752 | F1-Score: 0.3474\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "\n",
            "--- Round 30/30 ---\n",
            "Train Loss (clients): 0.2731 | Test Loss: 1.2928\n",
            "Accuracy: 0.8241 | Precision: 0.3389 | Recall: 0.3814 | F1-Score: 0.3572\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "\n",
            "--- Round 5/30 ---\n",
            "Train Loss (clients): 0.2778 | Test Loss: 1.0417\n",
            "Accuracy: 0.8125 | Precision: 0.3265 | Recall: 0.3762 | F1-Score: 0.3492\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 10/30 ---\n",
            "Train Loss (clients): 0.2047 | Test Loss: 0.8713\n",
            "Accuracy: 0.8171 | Precision: 0.3290 | Recall: 0.3788 | F1-Score: 0.3518\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 15/30 ---\n",
            "Train Loss (clients): 0.1647 | Test Loss: 0.7418\n",
            "Accuracy: 0.8237 | Precision: 0.3385 | Recall: 0.3813 | F1-Score: 0.3570\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "\n",
            "--- Round 20/30 ---\n",
            "Train Loss (clients): 0.1417 | Test Loss: 0.6841\n",
            "Accuracy: 0.8250 | Precision: 0.3388 | Recall: 0.3822 | F1-Score: 0.3577\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 25/30 ---\n",
            "Train Loss (clients): 0.1232 | Test Loss: 0.5751\n",
            "Accuracy: 0.8278 | Precision: 0.3396 | Recall: 0.3835 | F1-Score: 0.3587\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "\n",
            "--- Round 30/30 ---\n",
            "Train Loss (clients): 0.1092 | Test Loss: 0.5972\n",
            "Accuracy: 0.8315 | Precision: 0.5474 | Recall: 0.3874 | F1-Score: 0.3676\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "\n",
            "--- Round 5/30 ---\n",
            "Train Loss (clients): 0.3988 | Test Loss: 1.4468\n",
            "Accuracy: 0.7221 | Precision: 0.3994 | Recall: 0.4185 | F1-Score: 0.3935\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "\n",
            "--- Round 10/30 ---\n",
            "Train Loss (clients): 0.4495 | Test Loss: 1.3643\n",
            "Accuracy: 0.8207 | Precision: 0.3341 | Recall: 0.3806 | F1-Score: 0.3549\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 15/30 ---\n",
            "Train Loss (clients): 0.1900 | Test Loss: 1.0744\n",
            "Accuracy: 0.8194 | Precision: 0.3328 | Recall: 0.3802 | F1-Score: 0.3542\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 20/30 ---\n",
            "Train Loss (clients): 0.1756 | Test Loss: 0.7623\n",
            "Accuracy: 0.8270 | Precision: 0.5293 | Recall: 0.3946 | F1-Score: 0.3826\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "--- Round 25/30 ---\n",
            "Train Loss (clients): 0.2216 | Test Loss: 0.9818\n",
            "Accuracy: 0.8248 | Precision: 0.3449 | Recall: 0.3819 | F1-Score: 0.3597\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "\n",
            "--- Round 30/30 ---\n",
            "Train Loss (clients): 0.1364 | Test Loss: 0.8324\n",
            "Accuracy: 0.8267 | Precision: 0.3465 | Recall: 0.3828 | F1-Score: 0.3608\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "=== CL vs FL Comparison ===\n",
            "Metric          CL Mean±Std               FL Mean±Std               p-value   \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'test_accuracy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6367cbf46240>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;31m# Call the comparison function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m \u001b[0mprint_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfl_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-6367cbf46240>\u001b[0m in \u001b[0;36mprint_comparison\u001b[0;34m(cl_res, fl_res)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'Metric':<15} {'CL Mean±Std':<25} {'FL Mean±Std':<25} {'p-value':<10}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mcl_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'test_{metric}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcl_res\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mfl_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfl_res\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mt_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttest_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfl_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6367cbf46240>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'Metric':<15} {'CL Mean±Std':<25} {'FL Mean±Std':<25} {'p-value':<10}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mcl_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'test_{metric}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcl_res\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mfl_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfl_res\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mt_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttest_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfl_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'test_accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 4. Execution & Statistical Comparison (Corrected)\n",
        "# ======================\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "def print_comparison(cl_res, fl_res):\n",
        "    \"\"\"\n",
        "    Compare centralized (CL) vs. federated (FL) metrics using a two‐sample t‐test.\n",
        "    Assumes that each entry in `cl_res` and `fl_res` dictionaries\n",
        "    already contains keys: 'accuracy', 'precision', 'recall', 'f1'.\n",
        "    \"\"\"\n",
        "    print(\"\\n=== CL vs FL Comparison ===\")\n",
        "    print(f\"{'Metric':<15} {'CL Mean±Std':<25} {'FL Mean±Std':<25} {'p-value':<10}\")\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        cl_vals = [r[metric] for r in cl_res]    # <-- use 'accuracy', not 'test_accuracy'\n",
        "        fl_vals = [r[metric] for r in fl_res]\n",
        "        t_stat, p_val = stats.ttest_ind(cl_vals, fl_vals)\n",
        "        print(\n",
        "            f\"{metric.capitalize():<15} \"\n",
        "            f\"{np.mean(cl_vals):.4f}±{np.std(cl_vals):.4f} | \"\n",
        "            f\"{np.mean(fl_vals):.4f}±{np.std(fl_vals):.4f} | \"\n",
        "            f\"{p_val:.2e}{'*' if p_val < 0.05 else ''}\"\n",
        "        )\n",
        "\n",
        "# Call the corrected comparison function:\n",
        "print_comparison(cl_results, fl_results)\n"
      ],
      "metadata": {
        "id": "7Ca7nDoOlhda",
        "outputId": "f10073bc-6dab-4b0a-ddb1-e700d7e91b72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CL vs FL Comparison ===\n",
            "Metric          CL Mean±Std               FL Mean±Std               p-value   \n",
            "Accuracy        0.9294±0.0036 | 0.8274±0.0031 | 6.68e-06*\n",
            "Precision       0.9069±0.0399 | 0.4109±0.0965 | 2.56e-03*\n",
            "Recall          0.6959±0.0223 | 0.3839±0.0025 | 3.92e-05*\n",
            "F1              0.7386±0.0223 | 0.3619±0.0043 | 1.95e-05*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already run:\n",
        "# cl_results = [centralized_training(seed=s) for s in SEEDS]\n",
        "# fl_results = [run_fl_trial(seed=s)          for s in SEEDS]\n",
        "\n",
        "print(\"=== Centralized Learning Results ===\")\n",
        "for idx, seed in enumerate(SEEDS):\n",
        "    cl = cl_results[idx]\n",
        "    print(f\"\\n-- Seed {seed} --\")\n",
        "    # Training time\n",
        "    print(f\"Training Time (sec):   {cl['time']:.2f}\")\n",
        "    # Model size\n",
        "    print(f\"Model Size (MB):       {cl['model_size_mb']:.4f}\")\n",
        "    # (No communication cost in CL)\n",
        "    # Training RMSE and Test RMSE\n",
        "    print(f\"Train RMSE:            {cl['train_rmse']:.4f}\")\n",
        "    print(f\"Test  RMSE:            {cl['test_rmse']:.4f}\")\n",
        "    # Accuracy, Precision, Recall, F1\n",
        "    print(f\"Accuracy:              {cl['accuracy']:.4f}\")\n",
        "    print(f\"Precision:             {cl['precision']:.4f}\")\n",
        "    print(f\"Recall:                {cl['recall']:.4f}\")\n",
        "    print(f\"F1-Score:              {cl['f1']:.4f}\")\n",
        "\n",
        "print(\"\\n=== Federated Learning Results ===\")\n",
        "for idx, seed in enumerate(SEEDS):\n",
        "    fl = fl_results[idx]\n",
        "    print(f\"\\n-- Seed {seed} --\")\n",
        "    # Training time\n",
        "    print(f\"Training Time (sec):   {fl['train_time_sec']:.2f}\")\n",
        "    # Model size\n",
        "    print(f\"Model Size (MB):       {fl['model_size_mb']:.4f}\")\n",
        "    # Communication cost\n",
        "    print(f\"Comm. Cost (MB):       {fl['comm_cost_mb']:.2f}\")\n",
        "    # If you want final train loss instead of the whole curve:\n",
        "    last_train_loss = fl['train_losses'][-1]\n",
        "    print(f\"Final Train Loss:      {last_train_loss:.4f}\")\n",
        "    # Final test loss\n",
        "    print(f\"Final Test Loss:       {fl['final_test_loss']:.4f}\")\n",
        "    # Accuracy, Precision, Recall, F1\n",
        "    print(f\"Accuracy:              {fl['accuracy']:.4f}\")\n",
        "    print(f\"Precision:             {fl['precision']:.4f}\")\n",
        "    print(f\"Recall:                {fl['recall']:.4f}\")\n",
        "    print(f\"F1-Score:              {fl['f1']:.4f}\")\n"
      ],
      "metadata": {
        "id": "IJQPUy5HmIOQ",
        "outputId": "6684d47d-5b8f-4cfa-a8e3-6dab6e4b13fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Centralized Learning Results ===\n",
            "\n",
            "-- Seed 42 --\n",
            "Training Time (sec):   365.63\n",
            "Model Size (MB):       0.0528\n",
            "Train RMSE:            0.0269\n",
            "Test  RMSE:            0.8993\n",
            "Accuracy:              0.9299\n",
            "Precision:             0.9533\n",
            "Recall:                0.6707\n",
            "F1-Score:              0.7289\n",
            "\n",
            "-- Seed 123 --\n",
            "Training Time (sec):   385.55\n",
            "Model Size (MB):       0.0528\n",
            "Train RMSE:            0.0292\n",
            "Test  RMSE:            0.8213\n",
            "Accuracy:              0.9248\n",
            "Precision:             0.8558\n",
            "Recall:                0.6922\n",
            "F1-Score:              0.7175\n",
            "\n",
            "-- Seed 456 --\n",
            "Training Time (sec):   347.56\n",
            "Model Size (MB):       0.0528\n",
            "Train RMSE:            0.0284\n",
            "Test  RMSE:            0.6935\n",
            "Accuracy:              0.9335\n",
            "Precision:             0.9118\n",
            "Recall:                0.7248\n",
            "F1-Score:              0.7695\n",
            "\n",
            "=== Federated Learning Results ===\n",
            "\n",
            "-- Seed 42 --\n",
            "Training Time (sec):   78.58\n",
            "Model Size (MB):       0.0528\n",
            "Comm. Cost (MB):       31.65\n",
            "Final Train Loss:      0.2731\n",
            "Final Test Loss:       1.2928\n",
            "Accuracy:              0.8241\n",
            "Precision:             0.3389\n",
            "Recall:                0.3814\n",
            "F1-Score:              0.3572\n",
            "\n",
            "-- Seed 123 --\n",
            "Training Time (sec):   71.84\n",
            "Model Size (MB):       0.0528\n",
            "Comm. Cost (MB):       31.65\n",
            "Final Train Loss:      0.1092\n",
            "Final Test Loss:       0.5972\n",
            "Accuracy:              0.8315\n",
            "Precision:             0.5474\n",
            "Recall:                0.3874\n",
            "F1-Score:              0.3676\n",
            "\n",
            "-- Seed 456 --\n",
            "Training Time (sec):   73.23\n",
            "Model Size (MB):       0.0528\n",
            "Comm. Cost (MB):       31.65\n",
            "Final Train Loss:      0.1364\n",
            "Final Test Loss:       0.8324\n",
            "Accuracy:              0.8267\n",
            "Precision:             0.3465\n",
            "Recall:                0.3828\n",
            "F1-Score:              0.3608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def print_cl_vs_fl(cl_res, fl_res):\n",
        "    \"\"\"\n",
        "    Given:\n",
        "      - cl_res: list of dicts returned by centralized_training(...)\n",
        "                each dict has keys: 'accuracy', 'precision', 'recall', 'f1', etc.\n",
        "      - fl_res: list of dicts returned by run_fl_trial(...)\n",
        "                each dict has keys: 'accuracy', 'precision', 'recall', 'f1', etc.\n",
        "    This function prints a table of mean±std for CL vs FL (across seeds)\n",
        "    and the two‐sample t‐test p-value for each metric. A '*' is appended\n",
        "    if p < 0.05.\n",
        "    \"\"\"\n",
        "    print(\"\\n=== CL vs FL Comparison ===\")\n",
        "    print(f\"{'Metric':<15} {'CL Mean±Std':<25} {'FL Mean±Std':<25} {'p-value':<10}\")\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        # Extract the list of values across seeds\n",
        "        cl_vals = np.array([r[metric] for r in cl_res])\n",
        "        fl_vals = np.array([r[metric] for r in fl_res])\n",
        "        # Compute means and standard deviations\n",
        "        cl_mean, cl_std = cl_vals.mean(), cl_vals.std(ddof=0)\n",
        "        fl_mean, fl_std = fl_vals.mean(), fl_vals.std(ddof=0)\n",
        "        # Perform two‐sample t‐test (independent)\n",
        "        t_stat, p_val = stats.ttest_ind(cl_vals, fl_vals)\n",
        "        star = '*' if p_val < 0.05 else ''\n",
        "        # Print formatted\n",
        "        print(\n",
        "            f\"{metric.capitalize():<15} \"\n",
        "            f\"{cl_mean:.4f}±{cl_std:.4f} | \"\n",
        "            f\"{fl_mean:.4f}±{fl_std:.4f} | \"\n",
        "            f\"{p_val:.2e}{star}\"\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "# Call it:\n",
        "print_cl_vs_fl(cl_results, fl_results)\n"
      ],
      "metadata": {
        "id": "Lk8HHABZnvuc",
        "outputId": "ee56fb2a-b87b-4844-c418-0d0490bbfcff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CL vs FL Comparison ===\n",
            "Metric          CL Mean±Std               FL Mean±Std               p-value   \n",
            "Accuracy        0.9294±0.0036 | 0.8274±0.0031 | 6.68e-06*\n",
            "Precision       0.9069±0.0399 | 0.4109±0.0965 | 2.56e-03*\n",
            "Recall          0.6959±0.0223 | 0.3839±0.0025 | 3.92e-05*\n",
            "F1              0.7386±0.0223 | 0.3619±0.0043 | 1.95e-05*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "print(\"\\n=== CL vs FL Comparison (Additional + Train Loss) ===\")\n",
        "print(f\"{'Metric':<30} {'CL Mean±Std':<25} {'FL Mean±Std':<25} {'p-value':<10}\")\n",
        "\n",
        "# 1) Train Loss: CL uses 'train_rmse'; FL uses last element of 'train_losses'\n",
        "cl_train_losses = np.array([r['train_rmse'] for r in cl_results])\n",
        "fl_train_losses = np.array([r['train_losses'][-1] for r in fl_results])\n",
        "cl_mean, cl_std = cl_train_losses.mean(), cl_train_losses.std(ddof=0)\n",
        "fl_mean, fl_std = fl_train_losses.mean(), fl_train_losses.std(ddof=0)\n",
        "t_stat, p_val = stats.ttest_ind(cl_train_losses, fl_train_losses)\n",
        "star = '*' if p_val < 0.05 else ''\n",
        "print(\n",
        "    f\"{'Train Loss':<30} \"\n",
        "    f\"{cl_mean:.4f}±{cl_std:.4f} | \"\n",
        "    f\"{fl_mean:.4f}±{fl_std:.4f} | \"\n",
        "    f\"{p_val:.2e}{star}\"\n",
        ")\n",
        "\n",
        "# 2) Training Time: CL key='time'; FL key='train_time_sec'\n",
        "cl_times = np.array([r['time'] for r in cl_results])\n",
        "fl_times = np.array([r['train_time_sec'] for r in fl_results])\n",
        "cl_mean, cl_std = cl_times.mean(), cl_times.std(ddof=0)\n",
        "fl_mean, fl_std = fl_times.mean(), fl_times.std(ddof=0)\n",
        "t_stat, p_val = stats.ttest_ind(cl_times, fl_times)\n",
        "star = '*' if p_val < 0.05 else ''\n",
        "print(\n",
        "    f\"{'Training Time (sec)':<30} \"\n",
        "    f\"{cl_mean:.4f}±{cl_std:.4f} | \"\n",
        "    f\"{fl_mean:.4f}±{fl_std:.4f} | \"\n",
        "    f\"{p_val:.2e}{star}\"\n",
        ")\n",
        "\n",
        "# 3) Model Size (MB): both use 'model_size_mb'\n",
        "cl_models = np.array([r['model_size_mb'] for r in cl_results])\n",
        "fl_models = np.array([r['model_size_mb'] for r in fl_results])\n",
        "cl_mean, cl_std = cl_models.mean(), cl_models.std(ddof=0)\n",
        "fl_mean, fl_std = fl_models.mean(), fl_models.std(ddof=0)\n",
        "t_stat, p_val = stats.ttest_ind(cl_models, fl_models)\n",
        "star = '*' if p_val < 0.05 else ''\n",
        "print(\n",
        "    f\"{'Model Size (MB)':<30} \"\n",
        "    f\"{cl_mean:.4f}±{cl_std:.4f} | \"\n",
        "    f\"{fl_mean:.4f}±{fl_std:.4f} | \"\n",
        "    f\"{p_val:.2e}{star}\"\n",
        ")\n",
        "\n",
        "# 4) Test Loss: CL uses 'test_rmse'; FL uses 'final_test_loss'\n",
        "cl_test_losses = np.array([r['test_rmse'] for r in cl_results])\n",
        "fl_test_losses = np.array([r['final_test_loss'] for r in fl_results])\n",
        "cl_mean, cl_std = cl_test_losses.mean(), cl_test_losses.std(ddof=0)\n",
        "fl_mean, fl_std = fl_test_losses.mean(), fl_test_losses.std(ddof=0)\n",
        "t_stat, p_val = stats.ttest_ind(cl_test_losses, fl_test_losses)\n",
        "star = '*' if p_val < 0.05 else ''\n",
        "print(\n",
        "    f\"{'Test Loss':<30} \"\n",
        "    f\"{cl_mean:.4f}±{cl_std:.4f} | \"\n",
        "    f\"{fl_mean:.4f}±{fl_std:.4f} | \"\n",
        "    f\"{p_val:.2e}{star}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "wDC3MAeooaA9",
        "outputId": "62217706-f893-4f53-c531-6233cebca67f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CL vs FL Comparison (Additional + Train Loss) ===\n",
            "Metric                         CL Mean±Std               FL Mean±Std               p-value   \n",
            "Train Loss                     0.0282±0.0009 | 0.1729±0.0717 | 4.62e-02*\n",
            "Training Time (sec)            366.2462±15.5169 | 74.5495±2.9060 | 1.27e-05*\n",
            "Model Size (MB)                0.0528±0.0000 | 0.0528±0.0000 | nan\n",
            "Test Loss                      0.8047±0.0849 | 0.9075±0.2889 | 6.55e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-d0bf10934036>:40: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  t_stat, p_val = stats.ttest_ind(cl_models, fl_models)\n"
          ]
        }
      ]
    }
  ]
}