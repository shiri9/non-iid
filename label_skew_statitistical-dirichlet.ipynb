{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOrhiOfFEovaSC31CLnekKd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiri9/non-iid/blob/main/label_skew_statitistical-dirichlet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow and all dependencies explicitly compatible with TFF 0.87.0\n",
        "%pip install tensorflow==2.15.0\n",
        "%pip install tensorflow-federated==0.81.0\n",
        "%pip install tensorflow-privacy==0.9.0\n",
        "%pip install tensorflow-model-optimization==0.7.5\n",
        "%pip install jax==0.4.14 jaxlib==0.4.14\n",
        "%pip install google-vizier==0.1.11\n",
        "%pip install dp-accounting==0.4.3\n",
        "%pip install portpicker==1.6.0\n",
        "%pip install scipy==1.9.3\n",
        "%pip install numpy==1.25.2\n",
        "%pip install protobuf==3.20.3\n",
        "%pip install typing-extensions==4.7.1\n",
        "%pip install googleapis-common-protos==1.61.0\n",
        "%pip install dm-tree==0.1.8"
      ],
      "metadata": {
        "id": "Gz8B4VFI9q3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5gJVBJWLpy1",
        "outputId": "b4fae325-27e1-4db8-bfe0-acc9f124c1d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /usr/local/lib/python3.11/dist-packages/jax_plugins"
      ],
      "metadata": {
        "id": "ByDwyo9EOOYb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"TFF version:\", tff.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f8zXU4R6JmA",
        "outputId": "d6cac551-55a4-4f11-a9eb-04275948ca70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:Jax plugin configuration error: Plugin module jax_plugins.xla_cuda12 does not exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.14.1\n",
            "TFF version: 0.81.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "80QzDcra3UpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9244fb15-676a-4e09-a85e-e82493e9fe96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-63294c70e457>:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_train['labels'] = df_train['labels'].replace(attack_mapping)\n",
            "<ipython-input-3-63294c70e457>:30: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_test['labels'] = df_test['labels'].replace(attack_mapping)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in train set: [0 1 3 2 4]\n",
            "Unique labels in test set: [0 2 1 3 4]\n",
            "Train dataset shape: (125973, 40) (125973,)\n",
            "Test dataset shape: (22544, 40) (22544,)\n"
          ]
        }
      ],
      "source": [
        "#cell 1\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access data files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load datasets\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kdd_train.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kdd_test.csv')\n",
        "\n",
        "# Define label mapping for attack categories (including all labels from train and test sets)\n",
        "attack_mapping = {\n",
        "    'normal': 0, 'neptune': 1, 'land': 1, 'back': 1, 'teardrop': 1, 'pod': 1, 'smurf': 1,\n",
        "    'ipsweep': 2, 'nmap': 2, 'portsweep': 2, 'satan': 2,\n",
        "    'mailbomb': 1, 'apache2': 1, 'processtable': 1,  # Missing DoS labels in test set\n",
        "    'phf': 3, 'multihop': 3, 'warezclient': 3, 'warezmaster': 3, 'spy': 3, 'ftp_write': 3,\n",
        "    'guess_passwd': 3, 'imap': 3,\n",
        "    'buffer_overflow': 4, 'loadmodule': 4, 'perl': 4, 'rootkit': 4,\n",
        "    # Ensure all test labels are included\n",
        "    'mscan': 2, 'saint': 2, 'snmpgetattack': 3, 'snmpguess': 3, 'xlock': 3, 'xsnoop': 3,\n",
        "    'httptunnel': 3, 'ps': 4, 'xterm': 4,\n",
        "    'sendmail': 3, 'named': 3  # Missing labels in test set\n",
        "}\n",
        "\n",
        "# Apply the label mapping\n",
        "df_train['labels'] = df_train['labels'].replace(attack_mapping)\n",
        "df_test['labels'] = df_test['labels'].replace(attack_mapping)\n",
        "\n",
        "# Verify the unique labels after mapping\n",
        "print(\"Unique labels in train set:\", df_train['labels'].unique())\n",
        "print(\"Unique labels in test set:\", df_test['labels'].unique())\n",
        "\n",
        "# Dropping the irrelevant column 'num_outbound_cmds'\n",
        "df_train = df_train.drop('num_outbound_cmds', axis=1)\n",
        "df_test = df_test.drop('num_outbound_cmds', axis=1)\n",
        "\n",
        "# Encoding categorical columns: 'protocol_type', 'service', 'flag'\n",
        "categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df_train[col] = le.fit_transform(df_train[col])\n",
        "    df_test[col] = le.transform(df_test[col])  # Important: use transform for test set, not fit_transform\n",
        "\n",
        "# Scaling numerical columns\n",
        "numerical_columns = [\n",
        "    'duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'same_srv_rate',\n",
        "    'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
        "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_srv_diff_host_rate', 'dst_host_rerror_rate',\n",
        "    'dst_host_srv_rerror_rate', 'hot', 'num_compromised', 'num_root'\n",
        "]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_train[numerical_columns] = scaler.fit_transform(df_train[numerical_columns])\n",
        "df_test[numerical_columns] = scaler.transform(df_test[numerical_columns])\n",
        "\n",
        "# Convert to NumPy arrays and enforce correct types for TensorFlow\n",
        "X_train = np.array(df_train.drop('labels', axis=1)).astype(np.float32)\n",
        "y_train = np.array(df_train['labels']).astype(np.int32)\n",
        "\n",
        "X_test = np.array(df_test.drop('labels', axis=1)).astype(np.float32)\n",
        "y_test = np.array(df_test['labels']).astype(np.int32)\n",
        "\n",
        "# Convert to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
        "\n",
        "# Check dataset shapes\n",
        "print(\"Train dataset shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test dataset shape:\", X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cell2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Number of partitions (clients)\n",
        "num_partitions = 10\n",
        "\n",
        "# Define minimum number of samples to ensure visibility for each class\n",
        "min_samples_per_class = 50  # Set this to a value that ensures visibility\n",
        "\n",
        "# Get unique classes/labels in the dataset (assuming 5 classes)\n",
        "unique_labels_noniid = df_train['labels'].unique()\n",
        "num_classes = len(unique_labels_noniid)\n",
        "\n",
        "# Assign classes to each client. Adjusted for 5 classes\n",
        "# Each client will observe a subset of the available classes\n",
        "client_class_map = {\n",
        "    0: [0, 1],  # Client 1 observes classes 0 and 1\n",
        "    1: [0, 2],  # Client 2 observes classes 0 and 2\n",
        "    2: [0, 3],  # Client 3 observes classes 0 and 3\n",
        "    3: [0, 4],  # Client 4 observes classes 0 and 4\n",
        "    4: [1, 2],  # Client 5 observes classes 1 and 2\n",
        "    5: [1, 3],  # Client 6 observes classes 1 and 3\n",
        "    6: [1, 4],  # Client 7 observes classes 1 and 4\n",
        "    7: [2, 3],  # Client 8 observes classes 2 and 3\n",
        "    8: [2, 4],  # Client 9 observes classes 2 and 4\n",
        "    9: [3, 4]   # Client 10 observes classes 3 and 4\n",
        "}\n",
        "\n",
        "# Initialize list to store partitions\n",
        "data_partitions = []\n",
        "\n",
        "# For each partition (client), we only sample data from the assigned classes\n",
        "for i in range(num_partitions):\n",
        "    partition = pd.DataFrame()\n",
        "\n",
        "    # Get the classes this client is supposed to observe\n",
        "    client_classes = client_class_map[i]\n",
        "\n",
        "    # Iterate through each class assigned to the current client\n",
        "    for label in client_classes:\n",
        "        class_data = df_train[df_train['labels'] == label]\n",
        "\n",
        "        # Generate a random proportion for the current partition and class\n",
        "        proportion = np.random.uniform(0.05, 0.5)  # Random proportion between 5% and 50%\n",
        "\n",
        "        # Ensure at least `min_samples_per_class` samples are included for each class\n",
        "        num_samples = max(min_samples_per_class, int(len(class_data) * proportion))\n",
        "\n",
        "        # Randomly sample this number of instances from the class data\n",
        "        sampled_data = class_data.sample(n=num_samples, replace=False)\n",
        "\n",
        "        # Append the sampled data to the current partition\n",
        "        partition = pd.concat([partition, sampled_data])\n",
        "\n",
        "    # Shuffle the partition data and reset the index\n",
        "    partition = partition.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Add the partition to the list\n",
        "    data_partitions.append(partition)\n",
        "\n",
        "    # Display class distribution in this partition\n",
        "    print(f\"Partition {i+1} class distribution:\")\n",
        "    print(partition['labels'].value_counts())\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rKUQqdCvKrZ",
        "outputId": "b0a868e1-c5b5-46b4-d2c4-cc7b78a7c06b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partition 1 class distribution:\n",
            "labels\n",
            "0    27046\n",
            "1     3766\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Partition 2 class distribution:\n",
            "labels\n",
            "0    26311\n",
            "2     5139\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Partition 3 class distribution:\n",
            "labels\n",
            "0    4915\n",
            "3     165\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Partition 4 class distribution:\n",
            "labels\n",
            "0    14793\n",
            "4       50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Partition 5 class distribution:\n",
            "labels\n",
            "1    15258\n",
            "2     3878\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Partition 6 class distribution:\n",
            "labels\n",
            "1    18415\n",
            "3       57\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Partition 7 class distribution:\n",
            "labels\n",
            "1    8050\n",
            "4      50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Partition 8 class distribution:\n",
            "labels\n",
            "2    4521\n",
            "3     491\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Partition 9 class distribution:\n",
            "labels\n",
            "2    2226\n",
            "4      50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Partition 10 class distribution:\n",
            "labels\n",
            "3    95\n",
            "4    50\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Cell3: Create Label-Skew Partitions\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "NUM_CLIENTS = 10\n",
        "CLASS_MAPPING = {'Benign': 0, 'DoS': 1, 'Probe': 2, 'U2R': 3, 'R2L': 4}\n",
        "MIN_SAMPLES_PER_CLASS = 50  # Prevent class starvation\n",
        "\n",
        "# Label distribution per client (matches your paper's setup)\n",
        "client_class_map = {\n",
        "    0: ['Benign', 'DoS'],\n",
        "    1: ['Benign', 'Probe'],\n",
        "    2: ['Benign', 'U2R'],\n",
        "    3: ['Benign', 'R2L'],\n",
        "    4: ['DoS', 'Probe'],\n",
        "    5: ['DoS', 'U2R'],\n",
        "    6: ['DoS', 'R2L'],\n",
        "    7: ['Probe', 'U2R'],\n",
        "    8: ['Probe', 'R2L'],\n",
        "    9: ['U2R', 'R2L']\n",
        "}\n",
        "\n",
        "data_partitions = []\n",
        "for client_id in range(NUM_CLIENTS):\n",
        "    client_partition = pd.DataFrame()\n",
        "    classes = client_class_map[client_id]\n",
        "\n",
        "    for class_name in classes:\n",
        "        label = CLASS_MAPPING[class_name]\n",
        "        class_data = df_train[df_train['labels'] == label]\n",
        "\n",
        "        # Dynamic sampling with minimum guarantee\n",
        "        proportion = np.random.uniform(0.1, 0.4)  # 10-40% of class data\n",
        "        num_samples = max(MIN_SAMPLES_PER_CLASS, int(len(class_data) * proportion))\n",
        "\n",
        "        client_partition = pd.concat([\n",
        "            client_partition,\n",
        "            class_data.sample(n=num_samples, random_state=42+client_id)\n",
        "        ])\n",
        "\n",
        "    # Shuffle and store\n",
        "    data_partitions.append(\n",
        "        client_partition.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    # Verification\n",
        "    print(f\"\\nClient {client_id+1} Distribution:\")\n",
        "    print(client_partition['labels'].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKxCZ-BWvVou",
        "outputId": "01bbbcad-847b-48f7-8d91-889ebf60a20f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Client 1 Distribution:\n",
            "labels\n",
            "0    15098\n",
            "1    17091\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 2 Distribution:\n",
            "labels\n",
            "0    20927\n",
            "2     2774\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 3 Distribution:\n",
            "labels\n",
            "0    7598\n",
            "3     205\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 4 Distribution:\n",
            "labels\n",
            "0    7355\n",
            "4      50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 5 Distribution:\n",
            "labels\n",
            "1    8762\n",
            "2    4268\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 6 Distribution:\n",
            "labels\n",
            "1    12575\n",
            "3      389\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 7 Distribution:\n",
            "labels\n",
            "1    7528\n",
            "4      50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 8 Distribution:\n",
            "labels\n",
            "2    2738\n",
            "3     166\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 9 Distribution:\n",
            "labels\n",
            "2    2232\n",
            "4      50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 10 Distribution:\n",
            "labels\n",
            "3    131\n",
            "4     50\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Cell4 : Create TensorFlow Datasets (Final Corrected Version)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Configuration\n",
        "batch_size = 32\n",
        "SEED = 42  # For reproducible shuffling\n",
        "\n",
        "train_datasets = []\n",
        "val_datasets = []\n",
        "\n",
        "for client_id, partition in enumerate(data_partitions):\n",
        "    # ========== Exact 90/10 Split ==========\n",
        "    total_samples = len(partition)\n",
        "    train_samples = (total_samples // 10) * 9  # Exact 90%\n",
        "    val_samples = total_samples - train_samples  # Exact 10%\n",
        "\n",
        "    # Shuffle with client-specific seed\n",
        "    shuffled_partition = partition.sample(frac=1, random_state=SEED+client_id).reset_index(drop=True)\n",
        "\n",
        "    # Split into train/val\n",
        "    train_part = shuffled_partition.iloc[:train_samples]\n",
        "    val_part = shuffled_partition.iloc[train_samples:]\n",
        "\n",
        "    # ========== Feature/Label Conversion ==========\n",
        "    # Training data\n",
        "    train_features = train_part.drop(columns=['labels']).values.astype(np.float32)\n",
        "    train_labels = train_part['labels'].values.astype(np.int32)\n",
        "\n",
        "    # Validation data\n",
        "    val_features = val_part.drop(columns=['labels']).values.astype(np.float32)\n",
        "    val_labels = val_part['labels'].values.astype(np.int32)\n",
        "\n",
        "    # ========== Dataset Creation ==========\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (train_features, train_labels)\n",
        "    ).batch(batch_size)\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (val_features, val_labels)\n",
        "    ).batch(batch_size)\n",
        "\n",
        "    # Store datasets\n",
        "    train_datasets.append(train_dataset)\n",
        "    val_datasets.append(val_dataset)\n",
        "\n",
        "    # ========== Verification ==========\n",
        "    print(f\"Client {client_id+1}:\")\n",
        "    print(f\"  Train: {len(train_part)} samples | Classes: {np.unique(train_labels)}\")\n",
        "    print(f\"  Val: {len(val_part)} samples | Classes: {np.unique(val_labels)}\\n\")\n",
        "\n",
        "# ========== Test Dataset ==========\n",
        "test_features = df_test.drop(columns=['labels']).values.astype(np.float32)\n",
        "test_labels = df_test['labels'].values.astype(np.int32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_features, test_labels)\n",
        ").batch(batch_size)\n",
        "\n",
        "print(\"=== Final Verification ===\")\n",
        "print(f\"Total training clients: {len(train_datasets)}\")\n",
        "print(f\"Test samples: {len(test_labels)}\")\n",
        "print(f\"Test features shape: {test_features.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VISmOyIqvW74",
        "outputId": "1d1bf57a-810e-4d52-d888-0f7286725eb4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 1:\n",
            "  Train: 28962 samples | Classes: [0 1]\n",
            "  Val: 3227 samples | Classes: [0 1]\n",
            "\n",
            "Client 2:\n",
            "  Train: 21330 samples | Classes: [0 2]\n",
            "  Val: 2371 samples | Classes: [0 2]\n",
            "\n",
            "Client 3:\n",
            "  Train: 7020 samples | Classes: [0 3]\n",
            "  Val: 783 samples | Classes: [0 3]\n",
            "\n",
            "Client 4:\n",
            "  Train: 6660 samples | Classes: [0 4]\n",
            "  Val: 745 samples | Classes: [0 4]\n",
            "\n",
            "Client 5:\n",
            "  Train: 11727 samples | Classes: [1 2]\n",
            "  Val: 1303 samples | Classes: [1 2]\n",
            "\n",
            "Client 6:\n",
            "  Train: 11664 samples | Classes: [1 3]\n",
            "  Val: 1300 samples | Classes: [1 3]\n",
            "\n",
            "Client 7:\n",
            "  Train: 6813 samples | Classes: [1 4]\n",
            "  Val: 765 samples | Classes: [1 4]\n",
            "\n",
            "Client 8:\n",
            "  Train: 2610 samples | Classes: [2 3]\n",
            "  Val: 294 samples | Classes: [2 3]\n",
            "\n",
            "Client 9:\n",
            "  Train: 2052 samples | Classes: [2 4]\n",
            "  Val: 230 samples | Classes: [2 4]\n",
            "\n",
            "Client 10:\n",
            "  Train: 162 samples | Classes: [3 4]\n",
            "  Val: 19 samples | Classes: [3 4]\n",
            "\n",
            "=== Final Verification ===\n",
            "Total training clients: 10\n",
            "Test samples: 22544\n",
            "Test features shape: (22544, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Cell5: Centralized Training (Label Skew Version)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def centralized_training(seed=42):\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "\n",
        "    # 1. Combine all client partitions (NEW FOR LABEL SKEW)\n",
        "    full_train = pd.concat(data_partitions).sample(frac=1, random_state=seed)\n",
        "    full_train_features = full_train.drop('labels', axis=1).values.astype(np.float32)\n",
        "    full_train_labels = full_train['labels'].values.astype(np.int32)\n",
        "\n",
        "    # 2. Create model (same architecture as FL)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # 3. Training with metrics tracking\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(\n",
        "        full_train_features, full_train_labels,\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        validation_data=(test_features, test_labels),  # Use your existing test data\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # 4. Final evaluation\n",
        "    y_pred = np.argmax(model.predict(test_features), axis=1)\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'train_loss': history.history['loss'],\n",
        "        'val_loss': history.history['val_loss'],\n",
        "        'test_accuracy': history.history['val_accuracy'][-1],\n",
        "        'test_precision': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'test_recall': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'test_f1': f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    }\n",
        "\n",
        "# Run with multiple seeds\n",
        "results_cl = [centralized_training(seed=s) for s in [42, 123, 456]]\n",
        "\n",
        "# Generate report\n",
        "report_cl = pd.DataFrame(results_cl)\n",
        "print(\"\\nCentralized Training Results (Label Skew Scenario):\")\n",
        "display(report_cl[['seed', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "06lTg3OVvh8L",
        "outputId": "ad9474ee-f949-406e-fa8d-437d2fd338b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Centralized Training Results (Label Skew Scenario):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   seed  test_accuracy  test_precision  test_recall   test_f1\n",
              "0    42       0.926056        0.933264     0.687010  0.737093\n",
              "1   123       0.924015        0.865954     0.685259  0.717707\n",
              "2   456       0.925169        0.852854     0.696172  0.717019"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcdfa898-0d1d-41d0-be20-e913ec1a29dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seed</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42</td>\n",
              "      <td>0.926056</td>\n",
              "      <td>0.933264</td>\n",
              "      <td>0.687010</td>\n",
              "      <td>0.737093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>123</td>\n",
              "      <td>0.924015</td>\n",
              "      <td>0.865954</td>\n",
              "      <td>0.685259</td>\n",
              "      <td>0.717707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>456</td>\n",
              "      <td>0.925169</td>\n",
              "      <td>0.852854</td>\n",
              "      <td>0.696172</td>\n",
              "      <td>0.717019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcdfa898-0d1d-41d0-be20-e913ec1a29dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fcdfa898-0d1d-41d0-be20-e913ec1a29dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fcdfa898-0d1d-41d0-be20-e913ec1a29dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-241936f3-71e9-44c5-b480-01376cc80b0f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-241936f3-71e9-44c5-b480-01376cc80b0f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-241936f3-71e9-44c5-b480-01376cc80b0f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(report_cl[['seed', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']])\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"seed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 219,\n        \"min\": 42,\n        \"max\": 456,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          42,\n          123,\n          456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001023111469315569,\n        \"min\": 0.9240152835845947,\n        \"max\": 0.9260557293891907,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9260557293891907,\n          0.9240152835845947,\n          0.9251685738563538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04314350390770069,\n        \"min\": 0.8528535777029049,\n        \"max\": 0.933264432101045,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.933264432101045,\n          0.8659544543703357,\n          0.8528535777029049\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005860541234303706,\n        \"min\": 0.6852592859201561,\n        \"max\": 0.6961716173363465,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6870102393570933,\n          0.6852592859201561,\n          0.6961716173363465\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011396668842593185,\n        \"min\": 0.7170185945155338,\n        \"max\": 0.737093431655716,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.737093431655716,\n          0.717707063012511,\n          0.7170185945155338\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Cell6: Federated Learning with Statistical Significance\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import collections\n",
        "from scipy import stats\n",
        "\n",
        "# ======================\n",
        "# 1. Data Preprocessing\n",
        "# ======================\n",
        "\n",
        "def preprocess(dataset):\n",
        "    def batch_format_fn(features, labels):\n",
        "        return collections.OrderedDict(\n",
        "            x=tf.reshape(features, [-1, 40]),  # Flatten features\n",
        "            y=tf.reshape(labels, [-1])  # Reshape labels\n",
        "        )\n",
        "    padded_shapes = ([None, 40], [None])\n",
        "    return dataset.padded_batch(32, padded_shapes=padded_shapes).map(batch_format_fn).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# ======================\n",
        "# 2. Core FL Functions\n",
        "# ======================\n",
        "\n",
        "def create_keras_model():\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "def make_federated_data(client_data, client_ids):\n",
        "    \"\"\"Global function to create federated datasets\"\"\"\n",
        "    return [\n",
        "        preprocess(client_data[i])\n",
        "        for i in client_ids\n",
        "        if len(list(client_data[i])) > 0  # Filter empty datasets\n",
        "    ]\n",
        "\n",
        "def run_fl_trial(seed=42, num_rounds=30):\n",
        "    \"\"\"Run complete FL pipeline with specified seed\"\"\"\n",
        "    # Set all seeds\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Model function\n",
        "    def model_fn():\n",
        "        return tff.learning.models.from_keras_model(\n",
        "            create_keras_model(),\n",
        "            input_spec=federated_train_data[0].element_spec,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "        )\n",
        "\n",
        "    # Build training process\n",
        "    training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn,\n",
        "        client_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.001),\n",
        "        server_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.01)\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    state = training_process.initialize()\n",
        "    for _ in range(num_rounds):\n",
        "        state = training_process.next(state, federated_train_data).state\n",
        "\n",
        "    # Evaluation\n",
        "    eval_model = create_keras_model()\n",
        "    eval_model.set_weights(list(training_process.get_model_weights(state).trainable))\n",
        "    y_pred = np.argmax(eval_model.predict(test_features), axis=1)\n",
        "\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'f1': f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    }\n",
        "\n",
        "# ======================\n",
        "# 3. Execution & Analysis\n",
        "# ======================\n",
        "\n",
        "# Configuration\n",
        "NUM_CLIENTS = 10\n",
        "SEEDS = [42, 123, 456]\n",
        "\n",
        "# Create federated data (ensure train_datasets exists)\n",
        "federated_train_data = make_federated_data(train_datasets, list(range(NUM_CLIENTS)))\n",
        "\n",
        "# Run trials\n",
        "fl_results = [run_fl_trial(seed=s) for s in SEEDS]\n",
        "\n",
        "# Statistical comparison with centralized results (assuming results_cl exists)\n",
        "def print_stat_comparison(cl_results, fl_results):\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        cl_values = [r[f'test_{metric}'] for r in cl_results]\n",
        "        fl_values = [r[metric] for r in fl_results]\n",
        "        t_stat, p_value = stats.ttest_ind(cl_values, fl_values)\n",
        "\n",
        "        print(f\"\\n{metric.upper():<10} CL: {np.mean(cl_values):.4f} ± {np.std(cl_values):.4f}\")\n",
        "        print(f\"{'FL:':<10} {np.mean(fl_values):.4f} ± {np.std(fl_values):.4f}\")\n",
        "        print(f\"{'p-value:':<10} {p_value:.4e}{'*' if p_value < 0.05 else ''}\")\n",
        "\n",
        "print(\"\\n=== Statistical Significance ===\")\n",
        "print_stat_comparison(results_cl, fl_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXWIgedTwE4_",
        "outputId": "a25ede68-6954-4a09-b203-3b0acec76068"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "=== Statistical Significance ===\n",
            "\n",
            "ACCURACY   CL: 0.9251 ± 0.0008\n",
            "FL:        0.8724 ± 0.0328\n",
            "p-value:   8.5748e-02\n",
            "\n",
            "PRECISION  CL: 0.8840 ± 0.0352\n",
            "FL:        0.5449 ± 0.0063\n",
            "p-value:   1.7914e-04*\n",
            "\n",
            "RECALL     CL: 0.6895 ± 0.0048\n",
            "FL:        0.4811 ± 0.0665\n",
            "p-value:   1.1487e-02*\n",
            "\n",
            "F1         CL: 0.7239 ± 0.0093\n",
            "FL:        0.4791 ± 0.0770\n",
            "p-value:   1.1147e-02*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "unique_labels, counts = np.unique(y_test, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Class {label}: {count} samples ({count/len(y_test):.1%})\")"
      ],
      "metadata": {
        "id": "Aw0fvuKdElec",
        "outputId": "0e1c2969-0bef-4b4c-8d14-694ecedf3745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 11245 samples (49.9%)\n",
            "Class 1: 8095 samples (35.9%)\n",
            "Class 2: 2157 samples (9.6%)\n",
            "Class 3: 1009 samples (4.5%)\n",
            "Class 4: 38 samples (0.2%)\n"
          ]
        }
      ]
    }
  ]
}