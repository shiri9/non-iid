{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMghO/5YsF46vPA9supv5xS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiri9/non-iid/blob/main/label_skew_statitistical-dirichlet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow and all dependencies explicitly compatible with TFF 0.87.0\n",
        "%pip install tensorflow==2.15.0\n",
        "%pip install tensorflow-federated==0.81.0\n",
        "%pip install tensorflow-privacy==0.9.0\n",
        "%pip install tensorflow-model-optimization==0.7.5\n",
        "%pip install jax==0.4.14 jaxlib==0.4.14\n",
        "%pip install google-vizier==0.1.11\n",
        "%pip install dp-accounting==0.4.3\n",
        "%pip install portpicker==1.6.0\n",
        "%pip install scipy==1.9.3\n",
        "%pip install numpy==1.25.2\n",
        "%pip install protobuf==3.20.3\n",
        "%pip install typing-extensions==4.7.1\n",
        "%pip install googleapis-common-protos==1.61.0\n",
        "%pip install dm-tree==0.1.8"
      ],
      "metadata": {
        "id": "Gz8B4VFI9q3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5gJVBJWLpy1",
        "outputId": "b4fae325-27e1-4db8-bfe0-acc9f124c1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /usr/local/lib/python3.11/dist-packages/jax_plugins"
      ],
      "metadata": {
        "id": "ByDwyo9EOOYb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"TFF version:\", tff.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f8zXU4R6JmA",
        "outputId": "d6cac551-55a4-4f11-a9eb-04275948ca70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:Jax plugin configuration error: Plugin module jax_plugins.xla_cuda12 does not exist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.14.1\n",
            "TFF version: 0.81.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80QzDcra3UpT"
      },
      "outputs": [],
      "source": [
        "#cell 1\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access data files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load datasets\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kdd_train.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kdd_test.csv')\n",
        "\n",
        "# Define label mapping for attack categories (including all labels from train and test sets)\n",
        "attack_mapping = {\n",
        "    'normal': 0, 'neptune': 1, 'land': 1, 'back': 1, 'teardrop': 1, 'pod': 1, 'smurf': 1,\n",
        "    'ipsweep': 2, 'nmap': 2, 'portsweep': 2, 'satan': 2,\n",
        "    'mailbomb': 1, 'apache2': 1, 'processtable': 1,  # Missing DoS labels in test set\n",
        "    'phf': 3, 'multihop': 3, 'warezclient': 3, 'warezmaster': 3, 'spy': 3, 'ftp_write': 3,\n",
        "    'guess_passwd': 3, 'imap': 3,\n",
        "    'buffer_overflow': 4, 'loadmodule': 4, 'perl': 4, 'rootkit': 4,\n",
        "    # Ensure all test labels are included\n",
        "    'mscan': 2, 'saint': 2, 'snmpgetattack': 3, 'snmpguess': 3, 'xlock': 3, 'xsnoop': 3,\n",
        "    'httptunnel': 3, 'ps': 4, 'xterm': 4,\n",
        "    'sendmail': 3, 'named': 3  # Missing labels in test set\n",
        "}\n",
        "\n",
        "# Apply the label mapping\n",
        "df_train['labels'] = df_train['labels'].replace(attack_mapping)\n",
        "df_test['labels'] = df_test['labels'].replace(attack_mapping)\n",
        "\n",
        "# Verify the unique labels after mapping\n",
        "print(\"Unique labels in train set:\", df_train['labels'].unique())\n",
        "print(\"Unique labels in test set:\", df_test['labels'].unique())\n",
        "\n",
        "# Dropping the irrelevant column 'num_outbound_cmds'\n",
        "df_train = df_train.drop('num_outbound_cmds', axis=1)\n",
        "df_test = df_test.drop('num_outbound_cmds', axis=1)\n",
        "\n",
        "# Encoding categorical columns: 'protocol_type', 'service', 'flag'\n",
        "categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df_train[col] = le.fit_transform(df_train[col])\n",
        "    df_test[col] = le.transform(df_test[col])  # Important: use transform for test set, not fit_transform\n",
        "\n",
        "# Scaling numerical columns\n",
        "numerical_columns = [\n",
        "    'duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'same_srv_rate',\n",
        "    'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
        "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_srv_diff_host_rate', 'dst_host_rerror_rate',\n",
        "    'dst_host_srv_rerror_rate', 'hot', 'num_compromised', 'num_root'\n",
        "]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_train[numerical_columns] = scaler.fit_transform(df_train[numerical_columns])\n",
        "df_test[numerical_columns] = scaler.transform(df_test[numerical_columns])\n",
        "\n",
        "# Convert to NumPy arrays and enforce correct types for TensorFlow\n",
        "X_train = np.array(df_train.drop('labels', axis=1)).astype(np.float32)\n",
        "y_train = np.array(df_train['labels']).astype(np.int32)\n",
        "\n",
        "X_test = np.array(df_test.drop('labels', axis=1)).astype(np.float32)\n",
        "y_test = np.array(df_test['labels']).astype(np.int32)\n",
        "\n",
        "# Convert to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
        "\n",
        "# Check dataset shapes\n",
        "print(\"Train dataset shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test dataset shape:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Cell2: Create Non-IID Partitions with Dirichlet Label Skew (Modified Version)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "NUM_CLIENTS = 10\n",
        "NUM_CLASSES = 5  # Based on your 5 attack categories (0-4)\n",
        "ALPHA = 0.5      # Dirichlet concentration parameter (α=0.5 for moderate skew)\n",
        "SEED = 42        # For reproducibility\n",
        "MIN_SAMPLES_PER_CLIENT = 100  # Ensure clients have sufficient data\n",
        "\n",
        "np.random.seed(SEED)  # Fix randomness for reproducibility\n",
        "\n",
        "# Step 1: Generate client-specific label distributions using Dirichlet\n",
        "client_label_probs = np.random.dirichlet([ALPHA]*NUM_CLASSES, size=NUM_CLIENTS)\n",
        "\n",
        "# Initialize list to store partitions\n",
        "data_partitions = []\n",
        "\n",
        "# Create partitions using Dirichlet distributions\n",
        "for client_id in range(NUM_CLIENTS):\n",
        "    partition = pd.DataFrame()\n",
        "    client_probs = client_label_probs[client_id]  # Probability vector for this client\n",
        "\n",
        "    # For each class, sample data proportionally to Dirichlet probabilities\n",
        "    for label in range(NUM_CLASSES):\n",
        "        class_data = df_train[df_train['labels'] == label]\n",
        "        if len(class_data) == 0:\n",
        "            continue  # Skip empty classes\n",
        "\n",
        "        # Calculate number of samples for this class\n",
        "        num_samples = max(\n",
        "            MIN_SAMPLES_PER_CLIENT // NUM_CLASSES,  # Minimum guarantee\n",
        "            int(len(class_data) * client_probs[label])  # Dirichlet proportion\n",
        "        )\n",
        "\n",
        "        # Sample without replacement\n",
        "        sampled_data = class_data.sample(n=num_samples, replace=False, random_state=SEED+client_id)\n",
        "        partition = pd.concat([partition, sampled_data])\n",
        "\n",
        "    # Final checks\n",
        "    if len(partition) == 0:\n",
        "        raise ValueError(f\"Client {client_id} has no data!\")\n",
        "\n",
        "    # Shuffle and store\n",
        "    data_partitions.append(\n",
        "        partition.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    # Print verification\n",
        "    print(f\"\\nClient {client_id+1} Label Distribution (Dirichlet α={ALPHA}):\")\n",
        "    print(partition['labels'].value_counts().sort_index())\n",
        "    print(f\"Target distribution: {np.round(client_probs, 2)}\")\n",
        "\n",
        "print(\"\\nSuccessfully created Dirichlet-based non-IID partitions!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rKUQqdCvKrZ",
        "outputId": "014d3d4a-5a67-4cc2-b383-ab4e0124dc67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Client 1 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0     7854\n",
            "1    25164\n",
            "2      235\n",
            "3       20\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.12 0.55 0.02 0.   0.31]\n",
            "\n",
            "Client 2 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0       20\n",
            "1    35730\n",
            "2      273\n",
            "3       65\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.   0.78 0.02 0.07 0.13]\n",
            "\n",
            "Client 3 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    23786\n",
            "1     3526\n",
            "2     2181\n",
            "3       35\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.35 0.08 0.19 0.04 0.35]\n",
            "\n",
            "Client 4 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0       70\n",
            "1    38573\n",
            "2      268\n",
            "3      131\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.   0.84 0.02 0.13 0.  ]\n",
            "\n",
            "Client 5 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0     20\n",
            "1    754\n",
            "2    277\n",
            "3     73\n",
            "4     46\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.   0.02 0.02 0.07 0.89]\n",
            "\n",
            "Client 6 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    55215\n",
            "1     5767\n",
            "2       30\n",
            "3       20\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.82 0.13 0.   0.   0.05]\n",
            "\n",
            "Client 7 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    36580\n",
            "1     1835\n",
            "2      117\n",
            "3       20\n",
            "4       21\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.54 0.04 0.01 0.   0.4 ]\n",
            "\n",
            "Client 8 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0      20\n",
            "1    9662\n",
            "2    3309\n",
            "3     468\n",
            "4      20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.   0.21 0.28 0.47 0.03]\n",
            "\n",
            "Client 9 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    11667\n",
            "1    18907\n",
            "2       44\n",
            "3      199\n",
            "4       20\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.17 0.41 0.   0.2  0.21]\n",
            "\n",
            "Client 10 Label Distribution (Dirichlet α=0.5):\n",
            "labels\n",
            "0    8455\n",
            "1      20\n",
            "2      20\n",
            "3      45\n",
            "4      43\n",
            "Name: count, dtype: int64\n",
            "Target distribution: [0.13 0.   0.   0.05 0.83]\n",
            "\n",
            "Successfully created Dirichlet-based non-IID partitions!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Cell3: Create Label-Skew Partitions\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "NUM_CLIENTS = 10\n",
        "CLASS_MAPPING = {'Benign': 0, 'DoS': 1, 'Probe': 2, 'U2R': 3, 'R2L': 4}\n",
        "MIN_SAMPLES_PER_CLASS = 50  # Prevent class starvation\n",
        "\n",
        "# Label distribution per client (matches your paper's setup)\n",
        "client_class_map = {\n",
        "    0: ['Benign', 'DoS'],\n",
        "    1: ['Benign', 'Probe'],\n",
        "    2: ['Benign', 'U2R'],\n",
        "    3: ['Benign', 'R2L'],\n",
        "    4: ['DoS', 'Probe'],\n",
        "    5: ['DoS', 'U2R'],\n",
        "    6: ['DoS', 'R2L'],\n",
        "    7: ['Probe', 'U2R'],\n",
        "    8: ['Probe', 'R2L'],\n",
        "    9: ['U2R', 'R2L']\n",
        "}\n",
        "\n",
        "data_partitions = []\n",
        "for client_id in range(NUM_CLIENTS):\n",
        "    client_partition = pd.DataFrame()\n",
        "    classes = client_class_map[client_id]\n",
        "\n",
        "    for class_name in classes:\n",
        "        label = CLASS_MAPPING[class_name]\n",
        "        class_data = df_train[df_train['labels'] == label]\n",
        "\n",
        "        # Dynamic sampling with minimum guarantee\n",
        "        proportion = np.random.uniform(0.1, 0.4)  # 10-40% of class data\n",
        "        num_samples = max(MIN_SAMPLES_PER_CLASS, int(len(class_data) * proportion))\n",
        "\n",
        "        client_partition = pd.concat([\n",
        "            client_partition,\n",
        "            class_data.sample(n=num_samples, random_state=42+client_id)\n",
        "        ])\n",
        "\n",
        "    # Shuffle and store\n",
        "    data_partitions.append(\n",
        "        client_partition.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    # Verification\n",
        "    print(f\"\\nClient {client_id+1} Distribution:\")\n",
        "    print(client_partition['labels'].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKxCZ-BWvVou",
        "outputId": "57f53aad-6740-4578-9e31-17c9905236a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Client 1 Distribution:\n",
            "labels\n",
            "0    15025\n",
            "1    15002\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 2 Distribution:\n",
            "labels\n",
            "0    11356\n",
            "2     1434\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 3 Distribution:\n",
            "labels\n",
            "0    12588\n",
            "3      147\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 4 Distribution:\n",
            "labels\n",
            "0    25516\n",
            "4       50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 5 Distribution:\n",
            "labels\n",
            "1    13319\n",
            "2     4212\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 6 Distribution:\n",
            "labels\n",
            "1    15665\n",
            "3      155\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 7 Distribution:\n",
            "labels\n",
            "1    16890\n",
            "4       50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 8 Distribution:\n",
            "labels\n",
            "2    3989\n",
            "3     366\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 9 Distribution:\n",
            "labels\n",
            "2    2277\n",
            "4      50\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Client 10 Distribution:\n",
            "labels\n",
            "3    167\n",
            "4     50\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Cell4 : Create TensorFlow Datasets (Final Corrected Version)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Configuration\n",
        "batch_size = 32\n",
        "SEED = 42  # For reproducible shuffling\n",
        "\n",
        "train_datasets = []\n",
        "val_datasets = []\n",
        "\n",
        "for client_id, partition in enumerate(data_partitions):\n",
        "    # ========== Exact 90/10 Split ==========\n",
        "    total_samples = len(partition)\n",
        "    train_samples = (total_samples // 10) * 9  # Exact 90%\n",
        "    val_samples = total_samples - train_samples  # Exact 10%\n",
        "\n",
        "    # Shuffle with client-specific seed\n",
        "    shuffled_partition = partition.sample(frac=1, random_state=SEED+client_id).reset_index(drop=True)\n",
        "\n",
        "    # Split into train/val\n",
        "    train_part = shuffled_partition.iloc[:train_samples]\n",
        "    val_part = shuffled_partition.iloc[train_samples:]\n",
        "\n",
        "    # ========== Feature/Label Conversion ==========\n",
        "    # Training data\n",
        "    train_features = train_part.drop(columns=['labels']).values.astype(np.float32)\n",
        "    train_labels = train_part['labels'].values.astype(np.int32)\n",
        "\n",
        "    # Validation data\n",
        "    val_features = val_part.drop(columns=['labels']).values.astype(np.float32)\n",
        "    val_labels = val_part['labels'].values.astype(np.int32)\n",
        "\n",
        "    # ========== Dataset Creation ==========\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (train_features, train_labels)\n",
        "    ).batch(batch_size)\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (val_features, val_labels)\n",
        "    ).batch(batch_size)\n",
        "\n",
        "    # Store datasets\n",
        "    train_datasets.append(train_dataset)\n",
        "    val_datasets.append(val_dataset)\n",
        "\n",
        "    # ========== Verification ==========\n",
        "    print(f\"Client {client_id+1}:\")\n",
        "    print(f\"  Train: {len(train_part)} samples | Classes: {np.unique(train_labels)}\")\n",
        "    print(f\"  Val: {len(val_part)} samples | Classes: {np.unique(val_labels)}\\n\")\n",
        "\n",
        "# ========== Test Dataset ==========\n",
        "test_features = df_test.drop(columns=['labels']).values.astype(np.float32)\n",
        "test_labels = df_test['labels'].values.astype(np.int32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_features, test_labels)\n",
        ").batch(batch_size)\n",
        "\n",
        "print(\"=== Final Verification ===\")\n",
        "print(f\"Total training clients: {len(train_datasets)}\")\n",
        "print(f\"Test samples: {len(test_labels)}\")\n",
        "print(f\"Test features shape: {test_features.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VISmOyIqvW74",
        "outputId": "1a47d55b-300a-49d1-b1a3-406fbaae4e5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 1:\n",
            "  Train: 27018 samples | Classes: [0 1]\n",
            "  Val: 3009 samples | Classes: [0 1]\n",
            "\n",
            "Client 2:\n",
            "  Train: 11511 samples | Classes: [0 2]\n",
            "  Val: 1279 samples | Classes: [0 2]\n",
            "\n",
            "Client 3:\n",
            "  Train: 11457 samples | Classes: [0 3]\n",
            "  Val: 1278 samples | Classes: [0 3]\n",
            "\n",
            "Client 4:\n",
            "  Train: 23004 samples | Classes: [0 4]\n",
            "  Val: 2562 samples | Classes: [0 4]\n",
            "\n",
            "Client 5:\n",
            "  Train: 15777 samples | Classes: [1 2]\n",
            "  Val: 1754 samples | Classes: [1 2]\n",
            "\n",
            "Client 6:\n",
            "  Train: 14238 samples | Classes: [1 3]\n",
            "  Val: 1582 samples | Classes: [1 3]\n",
            "\n",
            "Client 7:\n",
            "  Train: 15246 samples | Classes: [1 4]\n",
            "  Val: 1694 samples | Classes: [1 4]\n",
            "\n",
            "Client 8:\n",
            "  Train: 3915 samples | Classes: [2 3]\n",
            "  Val: 440 samples | Classes: [2 3]\n",
            "\n",
            "Client 9:\n",
            "  Train: 2088 samples | Classes: [2 4]\n",
            "  Val: 239 samples | Classes: [2 4]\n",
            "\n",
            "Client 10:\n",
            "  Train: 189 samples | Classes: [3 4]\n",
            "  Val: 28 samples | Classes: [3 4]\n",
            "\n",
            "=== Final Verification ===\n",
            "Total training clients: 10\n",
            "Test samples: 22544\n",
            "Test features shape: (22544, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ## Cell5: Centralized Training (Label Skew Version)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def centralized_training(seed=42):\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "\n",
        "    # 1. Combine all client partitions (NEW FOR LABEL SKEW)\n",
        "    full_train = pd.concat(data_partitions).sample(frac=1, random_state=seed)\n",
        "    full_train_features = full_train.drop('labels', axis=1).values.astype(np.float32)\n",
        "    full_train_labels = full_train['labels'].values.astype(np.int32)\n",
        "\n",
        "    # 2. Create model (same architecture as FL)\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # 3. Training with metrics tracking\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(\n",
        "        full_train_features, full_train_labels,\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        validation_data=(test_features, test_labels),  # Use your existing test data\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # 4. Final evaluation\n",
        "    y_pred = np.argmax(model.predict(test_features), axis=1)\n",
        "\n",
        "    return {\n",
        "        'seed': seed,\n",
        "        'train_loss': history.history['loss'],\n",
        "        'val_loss': history.history['val_loss'],\n",
        "        'test_accuracy': history.history['val_accuracy'][-1],\n",
        "        'test_precision': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'test_recall': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'test_f1': f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    }\n",
        "\n",
        "# Run with multiple seeds\n",
        "results_cl = [centralized_training(seed=s) for s in [42, 123, 456]]\n",
        "\n",
        "# Generate report\n",
        "report_cl = pd.DataFrame(results_cl)\n",
        "print(\"\\nCentralized Training Results (Label Skew Scenario):\")\n",
        "display(report_cl[['seed', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "06lTg3OVvh8L",
        "outputId": "40cc7560-2493-4da7-86d4-fd6660ffc307"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "Centralized Training Results (Label Skew Scenario):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   seed  test_accuracy  test_precision  test_recall   test_f1\n",
              "0    42       0.929915        0.953275     0.670655  0.728932\n",
              "1   123       0.924814        0.855777     0.692183  0.717540\n",
              "2   456       0.933463        0.911781     0.724816  0.769453"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a9bead9-792f-4655-8559-16d4cd8e2a98\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seed</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_precision</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42</td>\n",
              "      <td>0.929915</td>\n",
              "      <td>0.953275</td>\n",
              "      <td>0.670655</td>\n",
              "      <td>0.728932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>123</td>\n",
              "      <td>0.924814</td>\n",
              "      <td>0.855777</td>\n",
              "      <td>0.692183</td>\n",
              "      <td>0.717540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>456</td>\n",
              "      <td>0.933463</td>\n",
              "      <td>0.911781</td>\n",
              "      <td>0.724816</td>\n",
              "      <td>0.769453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a9bead9-792f-4655-8559-16d4cd8e2a98')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a9bead9-792f-4655-8559-16d4cd8e2a98 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a9bead9-792f-4655-8559-16d4cd8e2a98');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c1452019-305e-4f9a-a646-475222e0c1ea\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1452019-305e-4f9a-a646-475222e0c1ea')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c1452019-305e-4f9a-a646-475222e0c1ea button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(report_cl[['seed', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']])\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"seed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 219,\n        \"min\": 42,\n        \"max\": 456,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          42,\n          123,\n          456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00434804269944619,\n        \"min\": 0.9248136878013611,\n        \"max\": 0.933463454246521,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9299148321151733,\n          0.9248136878013611,\n          0.933463454246521\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.048928556352541244,\n        \"min\": 0.8557768857175289,\n        \"max\": 0.9532747255363543,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9532747255363543,\n          0.8557768857175289,\n          0.9117811004678428\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02726950366364693,\n        \"min\": 0.6706554590019773,\n        \"max\": 0.7248161854346515,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6706554590019773,\n          0.6921825101976615,\n          0.7248161854346515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027284679535199766,\n        \"min\": 0.7175401194275619,\n        \"max\": 0.7694531093361618,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7289315080973939,\n          0.7175401194275619,\n          0.7694531093361618\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Cell6: Federated Learning with Statistical Significance\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import collections\n",
        "from scipy import stats\n",
        "\n",
        "# ======================\n",
        "# 1. Data Preprocessing\n",
        "# ======================\n",
        "\n",
        "def preprocess(dataset):\n",
        "    def batch_format_fn(features, labels):\n",
        "        return collections.OrderedDict(\n",
        "            x=tf.reshape(features, [-1, 40]),  # Flatten features\n",
        "            y=tf.reshape(labels, [-1])  # Reshape labels\n",
        "        )\n",
        "    padded_shapes = ([None, 40], [None])\n",
        "    return dataset.padded_batch(32, padded_shapes=padded_shapes).map(batch_format_fn).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# ======================\n",
        "# 2. Core FL Functions\n",
        "# ======================\n",
        "\n",
        "def create_keras_model():\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(40,)),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "def make_federated_data(client_data, client_ids):\n",
        "    \"\"\"Global function to create federated datasets\"\"\"\n",
        "    return [\n",
        "        preprocess(client_data[i])\n",
        "        for i in client_ids\n",
        "        if len(list(client_data[i])) > 0  # Filter empty datasets\n",
        "    ]\n",
        "\n",
        "def run_fl_trial(seed=42, num_rounds=30):\n",
        "    \"\"\"Run complete FL pipeline with specified seed\"\"\"\n",
        "    # Set all seeds\n",
        "    tf.keras.utils.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Model function\n",
        "    def model_fn():\n",
        "        return tff.learning.models.from_keras_model(\n",
        "            create_keras_model(),\n",
        "            input_spec=federated_train_data[0].element_spec,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "        )\n",
        "\n",
        "    # Build training process\n",
        "    training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn,\n",
        "        client_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.001),\n",
        "        server_optimizer_fn=lambda: tf.keras.optimizers.Adam(0.01)\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    state = training_process.initialize()\n",
        "    for _ in range(num_rounds):\n",
        "        state = training_process.next(state, federated_train_data).state\n",
        "\n",
        "    # Evaluation\n",
        "    eval_model = create_keras_model()\n",
        "    eval_model.set_weights(list(training_process.get_model_weights(state).trainable))\n",
        "    y_pred = np.argmax(eval_model.predict(test_features), axis=1)\n",
        "\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
        "        'f1': f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    }\n",
        "\n",
        "# ======================\n",
        "# 3. Execution & Analysis\n",
        "# ======================\n",
        "\n",
        "# Configuration\n",
        "NUM_CLIENTS = 10\n",
        "SEEDS = [42, 123, 456]\n",
        "\n",
        "# Create federated data (ensure train_datasets exists)\n",
        "federated_train_data = make_federated_data(train_datasets, list(range(NUM_CLIENTS)))\n",
        "\n",
        "# Run trials\n",
        "fl_results = [run_fl_trial(seed=s) for s in SEEDS]\n",
        "\n",
        "# Statistical comparison with centralized results (assuming results_cl exists)\n",
        "def print_stat_comparison(cl_results, fl_results):\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        cl_values = [r[f'test_{metric}'] for r in cl_results]\n",
        "        fl_values = [r[metric] for r in fl_results]\n",
        "        t_stat, p_value = stats.ttest_ind(cl_values, fl_values)\n",
        "\n",
        "        print(f\"\\n{metric.upper():<10} CL: {np.mean(cl_values):.4f} ± {np.std(cl_values):.4f}\")\n",
        "        print(f\"{'FL:':<10} {np.mean(fl_values):.4f} ± {np.std(fl_values):.4f}\")\n",
        "        print(f\"{'p-value:':<10} {p_value:.4e}{'*' if p_value < 0.05 else ''}\")\n",
        "\n",
        "print(\"\\n=== Statistical Significance ===\")\n",
        "print_stat_comparison(results_cl, fl_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXWIgedTwE4_",
        "outputId": "d0688b52-6e8f-4442-b16e-bcc411559a95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "705/705 [==============================] - 1s 1ms/step\n",
            "705/705 [==============================] - 2s 2ms/step\n",
            "705/705 [==============================] - 1s 2ms/step\n",
            "\n",
            "=== Statistical Significance ===\n",
            "\n",
            "ACCURACY   CL: 0.9294 ± 0.0036\n",
            "FL:        0.8395 ± 0.0114\n",
            "p-value:   4.3965e-04*\n",
            "\n",
            "PRECISION  CL: 0.9069 ± 0.0399\n",
            "FL:        0.4738 ± 0.0906\n",
            "p-value:   3.4658e-03*\n",
            "\n",
            "RECALL     CL: 0.6959 ± 0.0223\n",
            "FL:        0.4063 ± 0.0186\n",
            "p-value:   1.4659e-04*\n",
            "\n",
            "F1         CL: 0.7386 ± 0.0223\n",
            "FL:        0.3991 ± 0.0293\n",
            "p-value:   1.9983e-04*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "unique_labels, counts = np.unique(y_test, return_counts=True)\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"Class {label}: {count} samples ({count/len(y_test):.1%})\")"
      ],
      "metadata": {
        "id": "Aw0fvuKdElec",
        "outputId": "fecd3062-a573-4aaf-f6ed-78bc7cb92ae6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 11245 samples (49.9%)\n",
            "Class 1: 8095 samples (35.9%)\n",
            "Class 2: 2157 samples (9.6%)\n",
            "Class 3: 1009 samples (4.5%)\n",
            "Class 4: 38 samples (0.2%)\n"
          ]
        }
      ]
    }
  ]
}